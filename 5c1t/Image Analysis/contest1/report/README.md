# Изучение данных
После изучения данных обучающей и тестовой выборок можно сделать несколько наблюдений.  

*Наблюдение 1*. Изображения, вообще говоря, отличаются сильно, и для их классификации должно быть достаточно детерминированного алгоритма, основанного на гистограммных и других методах анализа изображений, не связанных с машинным обучением и deep learning.  

*Наблюдение 2*. Размер изображений не фиксирован ни в общем, ни в рамках каждого из классов.  

*Наблюдение 3*. Классы 0, 4, 5 представляются исключительно квадратными изображениями, а классы 1, 2, 3 — прямоугольными, но не квадратными.  

*Наблюдение 4*. В тестовой выборке встречаются изображения, повернутые на 0, 90, 180 или 270 градусов.

# Решение

## Основные идеи
Несмотря на наблюдение 1, хотелось все же попробовать применить сверточную нейронную сеть для классификации изображений (по причинам исключительно образовательным: нейронные сети приходится писать "с нуля" сильно реже, чем другие скрипты на Python, а опыт это несомненно полезный).

Выбор нейронных сетей в качестве основного алгоритма решения вкупе с наблюдением 2 вынуждал либо к приведению всех изображений к каким-то фиксированным размерам перед подачей на вход сети, либо к написанию сети, индифферентной к размерам входного изображения. Был выбран второй вариант по двум причинам:
* если выполнять масштабирование изображений (с сохранением соотношения сторон), то пришлось бы создавать по сети на каждое существующее в обучающей выборке соотношение сторон. При этом не было бы никаких гарантий, что в тестовой выборке не встретится такое соотношение, которого не было в обучающей выборке.
* Изменение размеров изображения сопряжено с потерями в их качестве.

## Подготовка данных
При подготовке данных были реализованы следующие идеи:
* исходная обучающая выборка была разбита на две: новую обучающую (80%) и валидационную (20%) для контроля переобучения сети; валидационная выборка было собрана из случайных 20% изображений из каждого класса;
* объединение в батчи размера, большего 1, тривиальным образом сделать нельзя, т.к. изображения имеют произвольные размеры;
* при формировании батча (функция `collect_batches`) каждое изображение поворачивается на 90 * k градусов, где k выбирается случайно из множества {0, 1, 2, 3}.


## Архитектура сети
Для реализации нейронной сети использовалась библиотека [Keras](https://keras.io) с бэкендом TensorFlow.
В качестве модели была выбрана [YOLO DarkNet](https://arxiv.org/abs/1506.02640) со следующей [архитектурой](model_128_blocks.png) (на схеме размер входа сети фиксирован, чтобы были видны изменения размеров; красным выделены DarkNet-блоки).

Сеть принимает батч изображений произвольного размера (при этом внутри батча размеры должны быть одинаковыми).
Далее, производится выделение признаков по следующей схеме:
1) понижение размерности изображения в 2 раза с помощью сверточного слоя;
2) применение пары DarkNet-блоков;
3) MaxPooling, затем Dropout (только при обучении);
4) повтор пунктов 2-3;
5) повтор пункта 2;
6) свертка для уменьшения количества признаков;
7) применение глобального MaxPooling (для извлечения локальных свойств изображения, например, наличие текста) и глобального AveragePooling (для извлечения глобальных свойств изображения, например, соотношение между количеством черных и белых пикселей);
8) конкатенация выходов глобальных MaxPooling и AveragePooling;
9) полносвязный слой с softmax-активацией, вычисляющий на выходе "вероятности" принадлежности изображения к каждому из классов.

## Посылки
1. Обучена нейронная сеть с вышеописанной архитектурой для классификации всех изображений на 6 классов.
Исследование ошибок показало, что сеть зачастую ошибается на следующих парах классов: (0, 2), (4, 3), где первый элемент пары — правильный класс, а второй — предсказанный алгоритмом. Стоит заметить, что изображения классов 0 и 4 — квадратные, а классов 2 и 3 — нет.
2. Обучены две независимые нейронные сети с вышеописанной архитектурой: одна — для классификации квадратных изображений на классы {0, 4, 5}, вторая — для классификации неквадратных изображений на классы {1, 2, 3}. Такое решение логичным образом вытекает из выводов об ошибках сети из первого решения.

## Результаты
В таблице представлено значение метрики accuracy для обоих решений на обучающей (train), валидационной (validation), тестовой публичной (test_public) и тестовой приватной (test_private) выборках.

|              | train | validation | test_public | test_private |
|--------------|-------|------------|-------------|--------------|
| one DarkNet  | 1.0   | 1.0        | 0.92000     | 0.91657      |
| two DarkNets | 1.0   | 1.0        | 0.99885     | 1.00000      |


# Что не было сделано
Ввиду того, что задание выполнялось за два вечера до окончания контеста, некоторые идеи, к сожалению, не были реализованы (случайно или намеренно).
* Пиксели всех изображений было бы хорошо привести к интервалу [-1, 1], т.е. выполнить преобразование `image = image / 255 * 2 - 1`. В решении изображения подавались на вход сети со значениями пикселей из множества {0, 255}.
* Хотелось бы также попробовать реализовать детерминированный алгоритм, не использующий методы машинного обучения и deep learning, и добиться с его помощью как минимум тех же результатов.
* Возможно было бы полезно единожды применить случайный поворот на 90k градусов ко всем изображениям валидационной выборки. Это позволило бы сделать стадию валидации более похожей на стадию тестирования и выявить недостатки сети уже на этой стадии. С другой стороны, это никак не повлияло бы на процесс обучения, т.к. значение функции потерь на валидации никак не влияет на процесс обучения сети.
