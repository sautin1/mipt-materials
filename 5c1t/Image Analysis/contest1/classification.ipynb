{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import itertools\n",
    "\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPool2D, GlobalAveragePooling2D, GlobalMaxPooling2D, LeakyReLU\n",
    "from keras.layers import merge, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from common.paths import PATH_PROJECT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarknetBlock:\n",
    "    def __init__(self, filters1, filters3, strides=(1, 1)):\n",
    "        self._filters1 = filters1\n",
    "        self._filters3 = filters3\n",
    "        self._strides = strides\n",
    "        \n",
    "    def __call__(self, input_layer, *args, **kwargs):\n",
    "        x = input_layer\n",
    "        for filters, kernel, strides in zip([self._filters1, self._filters3],\n",
    "                                            [(1, 1), (3, 3)],\n",
    "                                            [(1, 1), self._strides]):\n",
    "            x = Conv2D(filters, kernel, padding='same', strides=strides)(x)\n",
    "            x = LeakyReLU()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_model(class_count, is_train=False):\n",
    "    input_tensor = Input(shape=(None, 1, None, None))\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
    "    for filters in [16, 32, 64]:\n",
    "        x = DarknetBlock(filters, filters * 2)(x)\n",
    "        x = DarknetBlock(filters, filters * 2)(x)\n",
    "        x = MaxPool2D(pool_size=(2, 2), padding='same')(x)\n",
    "        if is_train:\n",
    "            x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Conv2D(class_count, (3, 3), padding='same')(x)\n",
    "    max_output = GlobalMaxPooling2D()(x)\n",
    "    average_output = GlobalAveragePooling2D()(x)\n",
    "    x = merge(inputs=[max_output, average_output], mode='sum', concat_axis=1)\n",
    "    x = Activation('softmax')(x)\n",
    "    return Model(inputs=[input_tensor], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_COUNT = 6\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_map(path):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def is_png_image(path):\n",
    "    return os.path.isfile(path) and os.path.splitext(path) == '.png'\n",
    "\n",
    "\n",
    "def get_image_paths(root):\n",
    "    def _get_image_paths():\n",
    "        for path, dirs, files in os.walk(root):\n",
    "            file_paths = map(lambda filename: join(path, filename), files)\n",
    "            images = filter(is_png_image, file_paths)\n",
    "            yield images\n",
    "    return itertools.chain.from_iterable(_get_image_paths())\n",
    "\n",
    "\n",
    "PATH_DATA = join(PATH_PROJECT, 'contest1', 'data')\n",
    "\n",
    "label_map = read_label_map(join(PATH_DATA, 'train_labels.csv'))\n",
    "images_paths_train = list(get_image_paths(join(PATH_DATA, 'train')))\n",
    "images_paths_test = list(get_image_paths(join(PATH_DATA, 'test')))\n",
    "labels_train = (for image_path in images_paths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE, TEST_SIZE = len(images_train), len(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(CLASS_COUNT, True)\n",
    "model.compile(optimizer=Adadelta, loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=data_generator,\n",
    "                              steps_per_epoch=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}