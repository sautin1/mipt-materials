{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPool2D, GlobalAveragePooling2D, GlobalMaxPooling2D, LeakyReLU\n",
    "from keras.layers import concatenate, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from paths import PATH_DATA, PATH_PROJECT\n",
    "from iterators import roundrobin, repeat_infinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DarknetBlock:\n",
    "    def __init__(self, filters1, filters3, strides=(1, 1)):\n",
    "        self._filters1 = filters1\n",
    "        self._filters3 = filters3\n",
    "        self._strides = strides\n",
    "        \n",
    "    def __call__(self, input_layer, *args, **kwargs):\n",
    "        x = input_layer\n",
    "        for filters, kernel, strides in zip([self._filters1, self._filters3],\n",
    "                                            [(1, 1), (3, 3)],\n",
    "                                            [(1, 1), self._strides]):\n",
    "            x = Conv2D(filters, kernel, padding='same', strides=strides)(x)\n",
    "            x = LeakyReLU()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_model(class_count, is_train=False):\n",
    "    input_tensor = Input(shape=(1, None, None))\n",
    "    x = Conv2D(10, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
    "    filters = [20, 30, 40]\n",
    "    for idx, filter_size in enumerate(filters):\n",
    "        x = DarknetBlock(filter_size, filter_size * 2)(x)\n",
    "        x = DarknetBlock(filter_size, filter_size * 2)(x)\n",
    "        if idx < len(filters) - 1:\n",
    "            x = MaxPool2D(pool_size=(2, 2), padding='same')(x)\n",
    "            if is_train:\n",
    "                x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Conv2D(filters[-1], (1, 1), padding='same')(x)\n",
    "    max_output = GlobalMaxPooling2D()(x)\n",
    "    average_output = GlobalAveragePooling2D()(x)\n",
    "    x = concatenate(inputs=[max_output, average_output], axis=1)\n",
    "    x = Dense(class_count, activation='softmax')(x)\n",
    "    return Model(inputs=[input_tensor], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 5]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# cannot make bigger batches because images are of different size\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "SQUARE_COUNT = 3000\n",
    "TRAIN_SQUARE_SIZE = SQUARE_COUNT * 80 // 100\n",
    "VAL_SQUARE_SIZE = SQUARE_COUNT - TRAIN_SQUARE_SIZE\n",
    "\n",
    "RECT_COUNT = 4000\n",
    "TRAIN_RECT_SIZE = RECT_COUNT * 80 // 100\n",
    "VAL_RECT_SIZE = RECT_COUNT - TRAIN_RECT_SIZE\n",
    "\n",
    "CLASS_COUNT = 6\n",
    "CLASSES_SQUARE = [0, 4, 5]\n",
    "CLASSES_RECT = list(set(range(CLASS_COUNT)) - set(CLASSES_SQUARE))\n",
    "\n",
    "print(CLASSES_SQUARE)\n",
    "print(CLASSES_RECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_label_map(path):\n",
    "    with open(path, 'r') as fin:\n",
    "        reader = csv.reader(fin, delimiter=',')\n",
    "        # ignore header\n",
    "        next(reader)\n",
    "        label_map = {filename: int(label) for filename, label in reader}\n",
    "    return label_map\n",
    "\n",
    "\n",
    "def get_images_paths(root, labels):\n",
    "    dir_paths = list(map(lambda label: join(root, str(label)), labels))\n",
    "    file_paths = [list(map(lambda filename: join(dir_path, filename), os.listdir(dir_path))) for dir_path in dir_paths]\n",
    "    return roundrobin(*file_paths)\n",
    "\n",
    "\n",
    "def get_train_data(path_images, labels, label_map):\n",
    "    paths = repeat_infinitely(get_images_paths, path_images, labels)\n",
    "    for path in paths:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise ValueError(f'Image cannot be read: {path}')\n",
    "        label = labels.index(label_map[os.path.basename(path)])\n",
    "        yield (np.expand_dims(image, 0),\n",
    "               to_categorical(label, len(labels))[0])\n",
    "\n",
    "\n",
    "def collect_batches(iterable, batch_size=32, randomize=False, probability=0.5, rotate=False):\n",
    "    while True:\n",
    "        images, labels = [], []\n",
    "        while len(images) < batch_size:\n",
    "            image, label = next(iterable)\n",
    "            if not randomize or np.random.rand() < probability:\n",
    "                if rotate:\n",
    "                    image = np.rot90(image, np.random.randint(0, 4), (1, 2))\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "        yield np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = read_label_map(join(PATH_DATA, 'train_labels.csv'))\n",
    "gen_square_train_data = get_train_data(join(PATH_DATA, 'train'), CLASSES_SQUARE, label_map)\n",
    "gen_rect_train_data = get_train_data(join(PATH_DATA, 'train'), CLASSES_RECT, label_map)\n",
    "gen_square_val_data = get_train_data(join(PATH_DATA, 'validation'), CLASSES_SQUARE, label_map)\n",
    "gen_rect_val_data = get_train_data(join(PATH_DATA, 'validation'), CLASSES_RECT, label_map)\n",
    "\n",
    "gen_square_train_batches = collect_batches(gen_square_train_data, BATCH_SIZE, randomize=True, rotate=True)\n",
    "gen_rect_train_batches = collect_batches(gen_rect_train_data, BATCH_SIZE, randomize=True, rotate=True)\n",
    "gen_square_val_batches = collect_batches(gen_square_val_data, BATCH_SIZE, randomize=False, rotate=False)\n",
    "gen_rect_val_batches = collect_batches(gen_rect_val_data, BATCH_SIZE, randomize=False, rotate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(gen_rect_train_batches)\n",
    "# print(x.shape)\n",
    "# print(y)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(x[0, 0], cmap='Greys_r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_square = build_model(len(CLASSES_SQUARE), is_train=True)\n",
    "model_rect = build_model(len(CLASSES_RECT), is_train=True)\n",
    "\n",
    "model_square.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rect.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "path_weights = join(PATH_PROJECT, 'backups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2400/2400 [==============================] - 37s - loss: 0.0304 - acc: 0.9892 - val_loss: 2.2560e-07 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "2400/2400 [==============================] - 33s - loss: 6.3925e-06 - acc: 1.0000 - val_loss: 1.2139e-07 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "2400/2400 [==============================] - 34s - loss: 0.0070 - acc: 0.9988 - val_loss: 1.5527e-07 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.2810e-07 - acc: 1.0000 - val_loss: 1.3918e-07 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.5892e-07 - acc: 1.0000 - val_loss: 1.2964e-07 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.2914e-07 - acc: 1.0000 - val_loss: 1.2805e-07 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.3034e-07 - acc: 1.0000 - val_loss: 1.2676e-07 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.2664e-07 - acc: 1.0000 - val_loss: 1.2587e-07 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.2236e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.2241e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2428e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2805e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2450e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2067e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2659e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.7124e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2147e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "2400/2400 [==============================] - 34s - loss: 1.2557e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.2659e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "2400/2400 [==============================] - 33s - loss: 1.3043e-07 - acc: 1.0000 - val_loss: 1.2577e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230e76cd128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_square.fit_generator(generator=gen_square_train_batches,\n",
    "                           steps_per_epoch=TRAIN_SQUARE_SIZE,\n",
    "                           epochs=20,\n",
    "                           validation_data=gen_square_val_batches,\n",
    "                           validation_steps=VAL_SQUARE_SIZE,\n",
    "                           callbacks=[ReduceLROnPlateau(patience=3),\n",
    "                                      ModelCheckpoint(join(path_weights, 'weights_square_{epoch:02d}'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3200/3200 [==============================] - 154s - loss: 0.0510 - acc: 0.9772 - val_loss: 3.0726e-07 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "3200/3200 [==============================] - 126s - loss: 1.4761e-07 - acc: 1.0000 - val_loss: 1.6719e-07 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "3200/3200 [==============================] - 127s - loss: 1.2716e-07 - acc: 1.0000 - val_loss: 1.5065e-07 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "3200/3200 [==============================] - 128s - loss: 1.3109e-07 - acc: 1.0000 - val_loss: 1.6041e-07 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "3200/3200 [==============================] - 130s - loss: 1.2478e-07 - acc: 1.0000 - val_loss: 1.2837e-07 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "3200/3200 [==============================] - 128s - loss: 1.2120e-07 - acc: 1.0000 - val_loss: 1.2934e-07 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "3200/3200 [==============================] - 125s - loss: 1.2180e-07 - acc: 1.0000 - val_loss: 1.3031e-07 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "3200/3200 [==============================] - 127s - loss: 1.2200e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "3200/3200 [==============================] - 128s - loss: 1.2364e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "3200/3200 [==============================] - 126s - loss: 1.2079e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "3200/3200 [==============================] - 127s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "3200/3200 [==============================] - 126s - loss: 1.2301e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "3200/3200 [==============================] - 129s - loss: 1.2161e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "3200/3200 [==============================] - 128s - loss: 1.2251e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "3200/3200 [==============================] - 127s - loss: 1.2139e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "3200/3200 [==============================] - 130s - loss: 1.2243e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "3200/3200 [==============================] - 122s - loss: 1.2482e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "3200/3200 [==============================] - 122s - loss: 1.2740e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "3200/3200 [==============================] - 122s - loss: 1.2375e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "3200/3200 [==============================] - 121s - loss: 1.2284e-07 - acc: 1.0000 - val_loss: 1.3091e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230e9cd0240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rect.fit_generator(generator=gen_rect_train_batches,\n",
    "                         steps_per_epoch=TRAIN_RECT_SIZE,\n",
    "                         epochs=20,\n",
    "                         validation_data=gen_rect_val_batches,\n",
    "                         validation_steps=VAL_RECT_SIZE,\n",
    "                         callbacks=[ReduceLROnPlateau(patience=3),\n",
    "                                    ModelCheckpoint(join(path_weights, 'weights_rect_{epoch:02d}'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_square_predict = build_model(len(CLASSES_SQUARE), is_train=False)\n",
    "model_rect_predict = build_model(len(CLASSES_RECT), is_train=False)\n",
    "\n",
    "model_square_predict.load_weights(join(path_weights, 'weights_square_19'))\n",
    "model_rect_predict.load_weights(join(path_weights, 'weights_rect_19'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_test = join(PATH_DATA, 'test')\n",
    "answers = {}\n",
    "for filename in os.listdir(path_test):\n",
    "    file_path = join(path_test, filename)\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    model_predict = model_square_predict\n",
    "    classes = CLASSES_SQUARE\n",
    "    if image.shape[0] != image.shape[1]:\n",
    "        model_predict = model_rect_predict\n",
    "        classes = CLASSES_RECT\n",
    "    tensor = image.reshape((1, 1, *image.shape))\n",
    "    label_categorical = model_predict.predict(tensor)\n",
    "    label = np.argmax(label_categorical)\n",
    "    answers[filename] = classes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(PATH_PROJECT, 'submission.csv'), 'w') as fout:\n",
    "    for filename, label in answers.items():\n",
    "        print(filename, label, file=fout, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
