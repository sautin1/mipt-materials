{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3 [10 баллов] \n",
    "# До 16.05.18 23:59\n",
    "\n",
    "Задание выполняется в группе (1-4 человека). В случае использования какого-либо строннего источника информации обязательно дайте на него ссылку (поскольку другие тоже могут на него наткнуться). Плагиат наказывается нулём баллов за задание и предвзятым отношением в будущем.\n",
    "\n",
    "Не все части обязательны для выполнения, однако вы можете быть дополнительно оштрафованы за небрежное за выполнение одной или двух частей вместо четырех.\n",
    "\n",
    "При возниконовении проблем с выполнением задания обращайтесь с вопросами к преподавателю. Поэтому настоятельно рекомендуется выполнять задание заранее, оставив запас времени на всевозможные технические проблемы. Если вы начали читать условие в последний вечер и не успели из-за проблем с установкой какой-либо библиотеки — это ваши проблемы.\n",
    "\n",
    "\n",
    "Результат выполнения задания — это отчёт в формате html на основе Jupyter Notebook. Нормальный отчёт должен включать в себя:\n",
    "* Краткую постановку задачи и формулировку задания\n",
    "* Описание **минимума** необходимой теории и/или описание используемых инструментов - не стоит переписывать лекции или Википедию\n",
    "* Подробный пошаговый рассказ о проделанной работе\n",
    "* Аккуратно оформленные результаты\n",
    "* **Внятные выводы** – не стоит относится к домашнему заданию как к последовательности сугубо технических шагов, а стоит относится скорее как к небольшому практическому исследованию, у которого есть своя цель и свое назначение.\n",
    "\n",
    "Небрежное его оформление отчета существенно отразится на итоговой оценке. Весь код из отчёта должен быть воспроизводимым, если для этого нужны какие-то дополнительные действия, установленные модули и т.п. — всё это должно быть прописано в тексте в явном виде.\n",
    "\n",
    "Сдача отчетов осуществляется через систему AnyTask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов с активным обучением\n",
    "\n",
    "\n",
    "Зададимся простой задачей классификации текстов: например, классификацией отзывов на банки по тональности. Эта задача решается с достаточно высокими показателями качества с использованием стандартных алгоритмов классификации, например, сверточных нейронных сетей: корпус состоит из достаточного количества документов, чтобы сверточная сеть хорошо обучилась. Однако возникает естественный вопрос: действительно ли все документы нужны для того, чтобы достичь таких высоких показателей качества (или сопоставимых с ними). Парадигма активного обучения поможет вам ответить на этот вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Предобработка данных [2 балла]\n",
    "\n",
    "Коллекция отзывов хранится в файле banki_responses (https://www.dropbox.com/s/ol3ux3ibr6rd5ke/banki_responses.json.bz2?dl=0). Одна строчка в этом файле соответствует одному json-словарю. Из этого словаря вам понадобятся два значения по ключам text и rating -- текст отзыва и его оценка по шкале от 1 до 5.   \n",
    "\n",
    "Считайте файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def split_into_words(sentence):\n",
    "    regexp = \"[^а-яА-ЯёЁa-zA-Z]\"\n",
    "    sentence = re.sub(regexp, \" \", sentence)\n",
    "    return sentence.lower().split()\n",
    "\n",
    "\n",
    "def read_data(path='./data/banki_responses.json'):\n",
    "    reviews = []\n",
    "    with open(path, 'r') as fin:\n",
    "        for line in fin:\n",
    "            reviews.append(json.loads(line.strip()))\n",
    "    return [{'text': review['text'],\n",
    "             'words': split_into_words(review['text']),\n",
    "             'rating': review['rating_grade']}\n",
    "            for review in reviews\n",
    "            if review['rating_grade'] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество отзывов: 136189.\n",
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reviews = read_data()\n",
    "print(f'Количество отзывов: {len(reviews)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте, каких отзывов больше: положительных (с оценкой 5) или отрицательных (с оценкой 1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество положительных отзывов: 26715.\n",
      "Количество отрицательных отзывов: 72307.\n",
      "Отрицательных отзывов больше.\n"
     ]
    }
   ],
   "source": [
    "reviews_positive_count = sum(1 for review in reviews if review['rating'] == 5)\n",
    "reviews_negative_count = sum(1 for review in reviews if review['rating'] == 1)\n",
    "print(f'Количество положительных отзывов: {reviews_positive_count}.')\n",
    "print(f'Количество отрицательных отзывов: {reviews_negative_count}.')\n",
    "print(('Положительных' if reviews_negative_count < reviews_positive_count else 'Отрицательных')\n",
    "      + ' отзывов больше.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите предварительную обработку данных: удалите слишком короткие и слишком длинные тексты (пороги на длину определите самостоятельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29b7de9ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Оценим распределение количества слов в отзывах, построив гистограмму.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist([len(review['words']) for review in reviews], 2000, facecolor='green', alpha=0.7)\n",
    "plt.xlabel('Review length (in words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Банк закрыт, на дверях замок.\n",
      "5: Банк хороший, обслуживаением доволен!\n",
      "5: Брал кредит все супер!\n",
      "5: Очень хороший банк! Вежливые сотрудники!\n",
      "1: Делают карту VISA почти 3 недели...\n",
      "3: Охранники у банка слишком злые.\n"
     ]
    }
   ],
   "source": [
    "# Оценим адекватность самых коротких отзывов,\n",
    "# чтобы выявить нижнюю границу на количество слов в отзыве выборки.\n",
    "\n",
    "for review in reviews:\n",
    "    if len(review['words']) <= 5:\n",
    "        print(f'{review[\"rating\"]}: {review[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество отзывов после фильтрации по количеству слов: 134911.\n"
     ]
    }
   ],
   "source": [
    "# Из гистограммы видно, что отзывов с количеством слов >= 1000, очень мало.\n",
    "# Поставим соответствующее ограничение сверху на количество слов в отзыве.\n",
    "\n",
    "# Из предыдущего примера можно видеть, что самые короткие отзывы состоят из 4-5 слов,\n",
    "# но при этом являются вполне адекватными, поэтому на текущем этапе причин для их удаления из выборки я не вижу.\n",
    "\n",
    "# Однако, заглядывая вперед, можно увидеть, что сверточной сети придется работать с изображениями большого разрешения:\n",
    "# (review_len, embedding_len),\n",
    "# где review_len -- количество слов в отзыве,\n",
    "# а embedding_len -- размер выходного вектора эмбеддинга.\n",
    "# Посему хорошо бы уменьшить разрешение на входе сетки, а также заметить,\n",
    "# что в ней будут использоваться pooling-слои, также понижающие размерность изображения.\n",
    "# По этой причине исходная длина отзыва (в словах) должна быть не меньше чем downsample factor сети.\n",
    "\n",
    "reviews = [review for review in reviews if 16 <= len(review['words']) < 1000]\n",
    "print(f'Количество отзывов после фильтрации по количеству слов: {len(reviews)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте данные на обучающее ($train$) и тестовое ($test$) множество случайным образом в отношеннии 3:1 (или любом другом отношении, которое покажется вам разумным).\n",
    "Задача классификации сформулирована так: по каждому отзыву определить его оценку (т.е. классификация на 5 классов). Признаками для классификации выступают слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В обучающей выборке 101183 отзывов.\n",
      "В тестовой выборке 33728 отзывов.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "TRAIN_PERCENT = 0.75\n",
    "\n",
    "reviews_indices_train = random.sample(list(range(len(reviews))),\n",
    "                                      int(TRAIN_PERCENT * len(reviews)))\n",
    "reviews_indices_test = list(set(range(len(reviews))) - set(reviews_indices_train))\n",
    "\n",
    "reviews_train = [reviews[idx] for idx in reviews_indices_train]\n",
    "reviews_test = [reviews[idx] for idx in reviews_indices_test]\n",
    "\n",
    "print(f'В обучающей выборке {len(reviews_train)} отзывов.')\n",
    "print(f'В тестовой выборке {len(reviews_test)} отзывов.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASautin\\AppData\\Local\\Continuum\\Anaconda2\\envs\\con3.6\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Загружаем fasttext модель, ограничиваясь первыми limit словами.\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "fasttext_model = KeyedVectors.load_word2vec_format('../hw2_senna/wiki.ru.vec', limit=999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_tensor_from_review(review, fasttext_model):\n",
    "    words = review['words']\n",
    "    tensor = np.zeros((len(words),))\n",
    "    for idx, word in enumerate(words):\n",
    "        word_in_vocab = fasttext_model.vocab.get(word, None)\n",
    "        if word_in_vocab is not None:\n",
    "            tensor[idx] = word_in_vocab.index\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "CLASS_COUNT = 5\n",
    "\n",
    "tensors_train = [make_tensor_from_review(review, fasttext_model) for review in reviews_train]\n",
    "tensors_test = [make_tensor_from_review(review, fasttext_model) for review in reviews_test]\n",
    "\n",
    "indices_train = sorted(list(range(len(tensors_train))), key=lambda idx: tensors_train[idx].shape[0])\n",
    "indices_test = sorted(list(range(len(tensors_test))), key=lambda idx: tensors_test[idx].shape[0])\n",
    "\n",
    "tensors_train_sorted = [tensors_train[idx] for idx in indices_train]\n",
    "tensors_test_sorted = [tensors_test[idx] for idx in indices_test]\n",
    "ratings_train_sorted = [to_categorical(reviews_train[idx]['rating'] - 1, CLASS_COUNT)\n",
    "                        for idx in indices_train]\n",
    "ratings_test_sorted = [to_categorical(reviews_test[idx]['rating'] - 1, CLASS_COUNT)\n",
    "                       for idx in indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество батчей в обучающей выборке: 6324.\n",
      "Количество батчей в тестовой выборке: 2108.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "batches_train_x = [tensors_train_sorted[idx:idx + BATCH_SIZE] for idx in range(0, len(tensors_train_sorted), BATCH_SIZE)]\n",
    "batches_train_y = [np.array(ratings_train_sorted[idx:idx + BATCH_SIZE]) for idx in range(0, len(ratings_train_sorted), BATCH_SIZE)]\n",
    "batches_test_x = [tensors_test_sorted[idx:idx + BATCH_SIZE] for idx in range(0, len(tensors_test_sorted), BATCH_SIZE)]\n",
    "batches_test_y = [np.array(ratings_test_sorted[idx:idx + BATCH_SIZE]) for idx in range(0, len(ratings_test_sorted), BATCH_SIZE)]\n",
    "\n",
    "batches_train_x = [pad_sequences(batch, padding='post') for batch in batches_train_x]\n",
    "batches_test_x = [pad_sequences(batch, padding='post') for batch in batches_test_x]\n",
    "\n",
    "print(f'Количество батчей в обучающей выборке: {len(batches_train_x)}.')\n",
    "print(f'Количество батчей в тестовой выборке: {len(batches_test_x)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_over_batches(batches_x, batches_y, randomize=False):\n",
    "    indices = list(range(len(batches_x)))\n",
    "    while True:\n",
    "        if randomize:\n",
    "            random.shuffle(indices)\n",
    "        for idx in indices:\n",
    "            yield batches_x[idx], batches_y[idx]\n",
    "\n",
    "\n",
    "gen_train = iterate_over_batches(batches_train_x, batches_train_y, randomize=True)\n",
    "gen_test = iterate_over_batches(batches_test_x, batches_test_y, randomize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# print(reviews_train[indices_train[idx]])\n",
    "# print(tensors_train_sorted[idx])\n",
    "# print(ratings_train_sorted[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Baseline [4 балла]\n",
    "\n",
    "Получите baseline классификации: в идеале, используйте сверточную нейронную сеть (слой эмбеддингов + свертка + субдескритизация). Число и размерность фильтров определите самостоятельно, так же как и использование регуляризаторов (dropout / batch norm) и их параметров. Так же самостоятельно (но обосновано) решите, использовать ли вам предобученные эмбеддинги или нет и проводить ли вам лемматизацию или нет. \n",
    "\n",
    "Обучите сеть на обучающем множестве и протестируйте на тестовом. Зафиксируйте baseline.\n",
    "\n",
    "Если совсем трудно или вычисления занимают слишком много времени, используйте любой другой известный и симпатичный вам алгоритм классификации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample factor: 16\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 300)         299999700 \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, None, 300)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, None, 150)     100       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, None, 75)      1820      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, None, 75)      5792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, None, 75)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, None, 75)      528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, None, 75)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, None, 75)      4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, None, 75)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, None, 75)      528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, None, 75)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, None, 38)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, None, 38)      64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, None, 38)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, None, 38)      9280      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, None, 38)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, None, 38)      2080      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, None, 38)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, None, 38)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64, None, 38)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, None, 38)      2080      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, None, 38)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, None, 19)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, None, 19)      128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, None, 19)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, None, 19)     36992     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 128, None, 19)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, None, 19)      8256      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 64, None, 19)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 128, None, 19)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 128, None, 19)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 64, None, 19)      8256      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 64, None, 19)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 5, None, 19)       325       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 300,172,921\n",
      "Trainable params: 173,125\n",
      "Non-trainable params: 299,999,796\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, MaxPool2D, Dropout\n",
    "from keras.layers import Reshape, BatchNormalization, LeakyReLU, Activation\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "class DarknetBlock:\n",
    "    def __init__(self, filters1, filters3, strides=(1, 1)):\n",
    "        self._filters1 = filters1\n",
    "        self._filters3 = filters3\n",
    "        self._strides = strides\n",
    "\n",
    "    def __call__(self, input_tensor, *args, **kwargs):\n",
    "        x = input_tensor\n",
    "        for filters, size, strides in [(self._filters3, (3, 3), self._strides),\n",
    "                                       (self._filters1, (1, 1), (1, 1))]:\n",
    "            x = Conv2D(filters, size, strides=strides, padding='same',\n",
    "                       kernel_initializer='he_normal', kernel_regularizer=l2(1e-10))(x)\n",
    "            x = LeakyReLU(alpha=0.05)(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def create_classifier_model(input_shape, class_count, fasttext_model, filter_counts=None):\n",
    "    filter_counts = filter_counts or [16, 32, 64]\n",
    "    downsample_factor = 1\n",
    "\n",
    "    # Пользуемся функционалом gensim.KeyedVectors для создания слоя Embedding.\n",
    "    # и инициализации его весами.\n",
    "    embedding_layer = fasttext_model.get_keras_embedding()\n",
    "    # Также отмечаем, что эти веса не надо менять при обучении сети.\n",
    "    embedding_layer.trainable = False\n",
    "\n",
    "    input_layer = Input(input_shape)\n",
    "    embedding = embedding_layer(input_layer)\n",
    "    reshaped = Reshape((1, -1, fasttext_model.vector_size))(embedding)\n",
    "    x = reshaped\n",
    "    x = Conv2D(10, (3, 3), strides=(2, 2), padding='same',\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(1e-10))(x)\n",
    "    downsample_factor *= 2\n",
    "    x = Conv2D(20, (3, 3), strides=(2, 2), padding='same',\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(1e-10))(x)\n",
    "    downsample_factor *= 2\n",
    "    for idx, filter_count in enumerate(filter_counts):\n",
    "        x = DarknetBlock(filter_count, filter_count * 2)(x)\n",
    "        x = DarknetBlock(filter_count, filter_count * 2)(x)\n",
    "        if idx != len(filter_counts) - 1:\n",
    "            x = MaxPool2D(pool_size=(2, 2), padding='same')(x)\n",
    "            downsample_factor *= 2\n",
    "            x = BatchNormalization(axis=1)(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "    x = Conv2D(class_count, (1, 1), padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax')(x)\n",
    "    return Model(inputs=[input_layer], outputs=[output]), downsample_factor\n",
    "\n",
    "\n",
    "classifier, downsample_factor = create_classifier_model((None,), CLASS_COUNT, fasttext_model)\n",
    "print(f'Downsample factor: {downsample_factor}')\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1054/1054 [==============================] - 135s 129ms/step - loss: 1.1140 - acc: 0.6105 - val_loss: 1.0412 - val_acc: 0.6368\n",
      "Epoch 2/50\n",
      "1054/1054 [==============================] - 105s 99ms/step - loss: 0.9970 - acc: 0.6570 - val_loss: 1.3660 - val_acc: 0.6002\n",
      "Epoch 3/50\n",
      "1054/1054 [==============================] - 105s 100ms/step - loss: 0.9771 - acc: 0.6586 - val_loss: 1.0299 - val_acc: 0.6422\n",
      "Epoch 4/50\n",
      "1054/1054 [==============================] - 104s 99ms/step - loss: 0.9678 - acc: 0.6610 - val_loss: 1.0874 - val_acc: 0.6490\n",
      "Epoch 5/50\n",
      "1054/1054 [==============================] - 113s 107ms/step - loss: 0.9383 - acc: 0.6750 - val_loss: 0.9952 - val_acc: 0.6540\n",
      "Epoch 6/50\n",
      "1054/1054 [==============================] - 103s 97ms/step - loss: 0.9332 - acc: 0.6747 - val_loss: 0.9194 - val_acc: 0.6788\n",
      "Epoch 7/50\n",
      "1054/1054 [==============================] - 108s 103ms/step - loss: 0.9297 - acc: 0.6699 - val_loss: 0.9456 - val_acc: 0.6678\n",
      "Epoch 8/50\n",
      "1054/1054 [==============================] - 103s 98ms/step - loss: 0.9173 - acc: 0.6775 - val_loss: 0.9637 - val_acc: 0.6770\n",
      "Epoch 9/50\n",
      "1054/1054 [==============================] - 99s 94ms/step - loss: 0.9262 - acc: 0.6727 - val_loss: 3.3367 - val_acc: 0.2447\n",
      "Epoch 10/50\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.9166 - acc: 0.6748 - val_loss: 1.1367 - val_acc: 0.6300\n",
      "Epoch 11/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.9145 - acc: 0.6775 - val_loss: 0.9418 - val_acc: 0.6687\n",
      "Epoch 12/50\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.9088 - acc: 0.6803\n",
      "Epoch 00012: reducing learning rate to 0.0005000000237487257.\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.9086 - acc: 0.6803 - val_loss: 2.0037 - val_acc: 0.3838\n",
      "Epoch 13/50\n",
      "1054/1054 [==============================] - 103s 97ms/step - loss: 0.8897 - acc: 0.6849 - val_loss: 0.9152 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "1054/1054 [==============================] - 100s 95ms/step - loss: 0.8816 - acc: 0.6849 - val_loss: 0.9765 - val_acc: 0.6625\n",
      "Epoch 15/50\n",
      "1054/1054 [==============================] - 113s 107ms/step - loss: 0.8836 - acc: 0.6809 - val_loss: 0.9530 - val_acc: 0.6727\n",
      "Epoch 16/50\n",
      "1054/1054 [==============================] - 101s 95ms/step - loss: 0.8820 - acc: 0.6862 - val_loss: 0.9122 - val_acc: 0.6753\n",
      "Epoch 17/50\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8882 - acc: 0.6860 - val_loss: 0.9090 - val_acc: 0.6769\n",
      "Epoch 18/50\n",
      "1054/1054 [==============================] - 100s 95ms/step - loss: 0.8764 - acc: 0.6875 - val_loss: 0.9423 - val_acc: 0.6734\n",
      "Epoch 19/50\n",
      "1054/1054 [==============================] - 105s 100ms/step - loss: 0.8693 - acc: 0.6879 - val_loss: 0.9224 - val_acc: 0.6753\n",
      "Epoch 20/50\n",
      "1054/1054 [==============================] - 108s 103ms/step - loss: 0.8727 - acc: 0.6858 - val_loss: 0.9102 - val_acc: 0.6788\n",
      "Epoch 21/50\n",
      "1054/1054 [==============================] - 99s 94ms/step - loss: 0.8687 - acc: 0.6885 - val_loss: 0.9285 - val_acc: 0.6728\n",
      "Epoch 22/50\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8680 - acc: 0.6891 - val_loss: 0.9159 - val_acc: 0.6801\n",
      "Epoch 23/50\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.8731 - acc: 0.6869\n",
      "Epoch 00023: reducing learning rate to 0.0002500000118743628.\n",
      "1054/1054 [==============================] - 103s 98ms/step - loss: 0.8735 - acc: 0.6868 - val_loss: 0.9344 - val_acc: 0.6728\n",
      "Epoch 24/50\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8725 - acc: 0.6890 - val_loss: 0.8997 - val_acc: 0.6819\n",
      "Epoch 25/50\n",
      "1054/1054 [==============================] - 99s 94ms/step - loss: 0.8560 - acc: 0.6880 - val_loss: 0.9481 - val_acc: 0.6738\n",
      "Epoch 26/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8524 - acc: 0.6914 - val_loss: 0.9303 - val_acc: 0.6708\n",
      "Epoch 27/50\n",
      "1054/1054 [==============================] - 102s 96ms/step - loss: 0.8555 - acc: 0.6946 - val_loss: 0.9115 - val_acc: 0.6807\n",
      "Epoch 28/50\n",
      "1054/1054 [==============================] - 103s 98ms/step - loss: 0.8588 - acc: 0.6903 - val_loss: 0.8911 - val_acc: 0.6836\n",
      "Epoch 29/50\n",
      "1054/1054 [==============================] - 103s 98ms/step - loss: 0.8531 - acc: 0.6898 - val_loss: 0.8941 - val_acc: 0.6834\n",
      "Epoch 30/50\n",
      "1054/1054 [==============================] - 100s 95ms/step - loss: 0.8381 - acc: 0.6944 - val_loss: 0.9198 - val_acc: 0.6779\n",
      "Epoch 31/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8350 - acc: 0.6971 - val_loss: 0.9316 - val_acc: 0.6739\n",
      "Epoch 32/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8518 - acc: 0.6938 - val_loss: 0.9236 - val_acc: 0.6769\n",
      "Epoch 33/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8436 - acc: 0.6941 - val_loss: 0.8911 - val_acc: 0.6842\n",
      "Epoch 34/50\n",
      "1053/1054 [============================>.] - ETA: 0s - loss: 0.8506 - acc: 0.6915\n",
      "Epoch 00034: reducing learning rate to 0.0001250000059371814.\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8508 - acc: 0.6913 - val_loss: 0.9036 - val_acc: 0.6794\n",
      "Epoch 35/50\n",
      "1054/1054 [==============================] - 109s 104ms/step - loss: 0.8452 - acc: 0.6914 - val_loss: 0.8993 - val_acc: 0.6805\n",
      "Epoch 36/50\n",
      "1054/1054 [==============================] - 102s 96ms/step - loss: 0.8322 - acc: 0.6952 - val_loss: 0.8956 - val_acc: 0.6836\n",
      "Epoch 37/50\n",
      "1054/1054 [==============================] - 103s 98ms/step - loss: 0.8417 - acc: 0.6938 - val_loss: 0.9317 - val_acc: 0.6761\n",
      "Epoch 38/50\n",
      "1054/1054 [==============================] - 100s 95ms/step - loss: 0.8269 - acc: 0.6973 - val_loss: 0.8899 - val_acc: 0.6858\n",
      "Epoch 39/50\n",
      "1054/1054 [==============================] - 102s 96ms/step - loss: 0.8267 - acc: 0.6960 - val_loss: 0.8915 - val_acc: 0.6860\n",
      "Epoch 40/50\n",
      "1054/1054 [==============================] - 108s 103ms/step - loss: 0.8244 - acc: 0.7012 - val_loss: 0.8990 - val_acc: 0.6814\n",
      "Epoch 41/50\n",
      "1054/1054 [==============================] - 104s 99ms/step - loss: 0.8381 - acc: 0.6923 - val_loss: 0.9011 - val_acc: 0.6830\n",
      "Epoch 42/50\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8347 - acc: 0.6965 - val_loss: 0.8817 - val_acc: 0.6888\n",
      "Epoch 43/50\n",
      "1054/1054 [==============================] - 100s 95ms/step - loss: 0.8345 - acc: 0.6929 - val_loss: 0.8936 - val_acc: 0.6864\n",
      "Epoch 44/50\n",
      "1054/1054 [==============================] - 103s 98ms/step - loss: 0.8279 - acc: 0.6957 - val_loss: 0.9020 - val_acc: 0.6789\n",
      "Epoch 45/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8332 - acc: 0.6950 - val_loss: 0.9198 - val_acc: 0.6791\n",
      "Epoch 46/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8103 - acc: 0.7063 - val_loss: 0.9490 - val_acc: 0.6726\n",
      "Epoch 47/50\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8317 - acc: 0.6954 - val_loss: 0.8826 - val_acc: 0.6879\n",
      "Epoch 48/50\n",
      "1052/1054 [============================>.] - ETA: 0s - loss: 0.8226 - acc: 0.6988\n",
      "Epoch 00048: reducing learning rate to 6.25000029685907e-05.\n",
      "1054/1054 [==============================] - 101s 96ms/step - loss: 0.8229 - acc: 0.6986 - val_loss: 0.8920 - val_acc: 0.6831\n",
      "Epoch 49/50\n",
      "1054/1054 [==============================] - 102s 97ms/step - loss: 0.8166 - acc: 0.7032 - val_loss: 0.8866 - val_acc: 0.6868\n",
      "Epoch 50/50\n",
      "1054/1054 [==============================] - 110s 104ms/step - loss: 0.8148 - acc: 0.7003 - val_loss: 0.8891 - val_acc: 0.6857\n",
      "{'acc': 0.7003083491461101, 'val_acc': 0.6856617647058824}\n"
     ]
    }
   ],
   "source": [
    "# Обучаем классификатор.\n",
    "# Сохраняем лог обучения и веса модели.\n",
    "\n",
    "import json\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=25, verbose=1),\n",
    "    ModelCheckpoint('weights/baseline_best', monitor='val_loss', period=5, save_best_only=True),\n",
    "]\n",
    "\n",
    "\n",
    "def process_training_results(model, history, name='main'):\n",
    "    with open(f'logs/{name}.json', 'w') as fout:\n",
    "        json.dump(history.history, fout, sort_keys=True, indent=4)\n",
    "    model.save_weights(f'weights/{name}')\n",
    "    return {'acc': history.history['acc'][-1], 'val_acc': history.history['val_acc'][-1]}\n",
    "\n",
    "\n",
    "history = classifier.fit_generator(gen_train, steps_per_epoch=len(batches_train_x) // 6,\n",
    "                                   epochs=50, callbacks=callbacks,\n",
    "                                   validation_data=gen_test, validation_steps=len(batches_test_x))\n",
    "metrics_baseline = process_training_results(classifier, history, name='baseline')\n",
    "print(metrics_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Baseline [4 балла] Активное обучение\n",
    "\n",
    "Подход активного обучения основан на следующей идее: вместо всего обучающего множества мы используем его маленькие фрагменты, в которых модель неуверена для обучения. Таким образом, модель обучается исключительно по **трудным** объектам, число которых существенно меньше, чем общее число объектов.\n",
    "\n",
    "Обучение модели начинается с обучения по $N$ случайно выбранным примерам, где $N$ – небольшое число (100, 200 и т.д.). Затем модель тестируется на $|train| - N$ объектах, после чего из  $|train| - N$ объектов выбираются снова $N$  объектов, в которых модель не уверена. Эти объекты используются для дообучения модели. Процесс выбора $N$ трудных объектов и дообучения на них повторяется некоторое количество раз (100, 200 и т.д. раз). На каждом шаге активного обучения модель можно протестировать на тестовом множестве, чтобы сравнить ее качества с baseline.\n",
    "\n",
    "Как выбирать трудные объекты:\n",
    "1. Выход нейронной сети - оценки 5 вероятностей принадлежности объекта одному из классов. Предсказанный класс – это тот класс, вероятность которого максимальна. Отсортируем объекты по убыванию вероятности предсказанного класса ($\\min \\max p_i$) и выберем $N$ первых объектов;\n",
    "2. Используем энтропию: чем больше энтропия предсказания, тем ближе распределение вероятностей предсказания к равномерному распределению, тем труднее объект. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
