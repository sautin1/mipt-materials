{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts matrix (n, m), representing an image, into a vector (n*m, )\n",
    "def img_to_row(img, index):\n",
    "    data = img.flatten().astype(float)\n",
    "    return data\n",
    "\n",
    "# returns a matrix representing a directory of images (row = image, column = pixel number)\n",
    "def img_dir_to_matrix(root_path, extension = '', need_names = False):\n",
    "    index = 0\n",
    "    data = None\n",
    "    filenames = []\n",
    "    for (path, dirs, files) in os.walk(root_path):\n",
    "        for filename in files:\n",
    "            if (filename.endswith(extension)):\n",
    "                fullpath = os.path.join(path, filename)\n",
    "                img = cv2.imread(fullpath, 0)\n",
    "                row = img_to_row(img, index)\n",
    "                if index == 0:\n",
    "                    data = row.reshape(1, -1)\n",
    "                else:\n",
    "                    data = np.vstack([data, row])\n",
    "                if need_names:\n",
    "                    filenames.append(filename)\n",
    "#                 if index == 5:\n",
    "#                     return (data, filenames) if need_names else data\n",
    "                index += 1\n",
    "                if index % 5000 == 0:\n",
    "                    print index\n",
    "    return (data, filenames) if need_names else data\n",
    "\n",
    "def export_to_csv(path, array, head = None):\n",
    "    frame = pd.DataFrame(array, columns=head)\n",
    "    frame.to_csv(path, sep = ',', header = (head != None), index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_train_class(root_path, extension, class_value):\n",
    "    train = img_dir_to_matrix(root_path, extension)\n",
    "    train_y = np.array([class_value] * train.shape[0])\n",
    "    return (train, train_y)\n",
    "    \n",
    "def generate_train_sample(root_path, extension, class_true_dir, class_false_dir):\n",
    "    if not root_path.endswith('/'):\n",
    "        root_path += '/'\n",
    "    print 'Generating training sample for True class'\n",
    "    train_true, train_true_y = generate_train_class(root_path + class_true_dir, extension, 1)\n",
    "    print 'Generating training sample for False class'\n",
    "    train_false, train_false_y = generate_train_class(root_path + class_false_dir, extension, 0)\n",
    "    \n",
    "    print 'Merging samples'\n",
    "    trainX = np.concatenate((train_true, train_false), 0)\n",
    "    trainY = np.concatenate((train_true_y, train_false_y), 0)\n",
    "    return (trainX, trainY)\n",
    "\n",
    "def generate_test_sample(root_path, extension):\n",
    "    print 'Generating test sample'\n",
    "    if not root_path.endswith('/'):\n",
    "        root_path += '/'\n",
    "    (data, filenames) = img_dir_to_matrix(root_path, extension, need_names=True)\n",
    "    test_ids = np.array([int(filename.split('.')[0]) for filename in filenames])\n",
    "    frame = pd.DataFrame(data)\n",
    "    frame['id'] = test_ids\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training sample for True class\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "Generating training sample for False class\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "Merging samples\n",
      "CPU times: user 10min 54s, sys: 4min 16s, total: 15min 11s\n",
      "Wall time: 15min 13s\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "CPU times: user 3min 54s, sys: 1min 35s, total: 5min 29s\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%time trainX, trainY = generate_train_sample('data/train/', '.tif', 'Hieroglyph', 'Other')\n",
    "%time test_frame = generate_test_sample('data/test/', '.tif')\n",
    "\n",
    "export_to_csv('data/train/trainX.csv', trainX)\n",
    "export_to_csv('data/train/trainY.csv', trainY)\n",
    "test_frame.to_csv('data/test/testX.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 99.1 ms, total: 2.99 s\n",
      "Wall time: 3 s\n",
      "CPU times: user 6.94 ms, sys: 0 ns, total: 6.94 ms\n",
      "Wall time: 6.74 ms\n",
      "CPU times: user 1.21 s, sys: 19.6 ms, total: 1.23 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%time trainX = pd.read_csv('data/train/trainX.csv', header=None, dtype=np.float32).values.reshape((-1, 1, 20, 20))\n",
    "%time trainY = pd.read_csv('data/train/trainY.csv', header=None, dtype=np.int32).values.reshape((-1))\n",
    "%time test_info = pd.read_csv('data/test/testX.csv')\n",
    "testIds = test_info['id'].values.astype(int)\n",
    "testX = test_info.drop('id', 1).values.astype(np.float32).reshape((-1, 1, 20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building convolutional neural net\n",
    "Architecture taken from:  \n",
    "https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py  \n",
    "build_cnn function  \n",
    "SAME AS #2, but with more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import lasagne.layers as layers\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.updates import adam\n",
    "from lasagne.updates import nesterov_momentum\n",
    "\n",
    "from nolearn.lasagne import NeuralNet, TrainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers0 = [\n",
    "    (layers.InputLayer, {'shape': (None, 1, 20, 20)}),\n",
    "\n",
    "    (layers.Conv2DLayer, {'num_filters': 32, 'filter_size': 5, 'nonlinearity': rectify}),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': 2}),\n",
    "\n",
    "    (layers.Conv2DLayer, {'num_filters': 32, 'filter_size': 5, 'nonlinearity': rectify}),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': 2}),\n",
    "\n",
    "    (layers.DenseLayer, {'num_units': 256, 'nonlinearity': rectify}),\n",
    "    (layers.DropoutLayer, {}),\n",
    "    (layers.DenseLayer, {'num_units': 10, 'nonlinearity': rectify}),\n",
    "\n",
    "    (layers.DenseLayer, {'num_units': 2, 'nonlinearity': softmax}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net0 = NeuralNet(\n",
    "    layers = layers0,\n",
    "    max_epochs = 500,\n",
    "    update = adam,\n",
    "    update_learning_rate = 0.0002,\n",
    "    objective_l2 = 0.0025,\n",
    "    train_split = TrainSplit(eval_size=0.16),\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 62080 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "name        size        total    cap.Y    cap.X    cov.Y    cov.X\n",
      "----------  --------  -------  -------  -------  -------  -------\n",
      "input0      1x20x20       400   100.00   100.00   100.00   100.00\n",
      "conv2d1     32x16x16     8192   100.00   100.00    25.00    25.00\n",
      "maxpool2d2  32x8x8       2048   100.00   100.00    25.00    25.00\n",
      "conv2d3     32x4x4        512    76.92    76.92    65.00    65.00\n",
      "maxpool2d4  32x2x2        128    76.92    76.92    65.00    65.00\n",
      "dense5      256           256   100.00   100.00   100.00   100.00\n",
      "dropout6    256           256   100.00   100.00   100.00   100.00\n",
      "dense7      10             10   100.00   100.00   100.00   100.00\n",
      "dense8      2               2   100.00   100.00   100.00   100.00\n",
      "\n",
      "Explanation\n",
      "    X, Y:    image dimensions\n",
      "    cap.:    learning capacity\n",
      "    cov.:    coverage of image\n",
      "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
      "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
      "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
      "\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -------\n",
      "      1       \u001b[36m1.19513\u001b[0m       \u001b[32m0.73284\u001b[0m      1.63083      0.93301  169.80s\n",
      "      2       \u001b[36m0.68422\u001b[0m       \u001b[32m0.61177\u001b[0m      1.11843      0.94821  169.01s\n",
      "      3       \u001b[36m0.57876\u001b[0m       \u001b[32m0.52965\u001b[0m      1.09273      0.95771  168.87s\n",
      "      4       \u001b[36m0.49797\u001b[0m       \u001b[32m0.46643\u001b[0m      1.06763      0.96339  170.07s\n",
      "      5       \u001b[36m0.42866\u001b[0m       \u001b[32m0.39570\u001b[0m      1.08331      0.96890  167.76s\n",
      "      6       \u001b[36m0.36275\u001b[0m       \u001b[32m0.34735\u001b[0m      1.04433      0.97009  168.44s\n",
      "      7       \u001b[36m0.30617\u001b[0m       \u001b[32m0.28740\u001b[0m      1.06529      0.97383  167.87s\n",
      "      8       \u001b[36m0.25833\u001b[0m       \u001b[32m0.24329\u001b[0m      1.06183      0.97887  169.85s\n",
      "      9       \u001b[36m0.21562\u001b[0m       \u001b[32m0.20854\u001b[0m      1.03391      0.97984  169.48s\n",
      "     10       \u001b[36m0.18045\u001b[0m       \u001b[32m0.17712\u001b[0m      1.01880      0.98162  168.61s\n",
      "     11       \u001b[36m0.15065\u001b[0m       \u001b[32m0.15324\u001b[0m      0.98310      0.98192  169.14s\n",
      "     12       \u001b[36m0.12649\u001b[0m       \u001b[32m0.13349\u001b[0m      0.94756      0.98385  169.79s\n",
      "     13       \u001b[36m0.10862\u001b[0m       \u001b[32m0.11891\u001b[0m      0.91346      0.98333  169.49s\n",
      "     14       \u001b[36m0.09341\u001b[0m       \u001b[32m0.10656\u001b[0m      0.87660      0.98497  167.62s\n",
      "     15       \u001b[36m0.08095\u001b[0m       \u001b[32m0.10414\u001b[0m      0.77735      0.98304  169.18s\n",
      "     16       \u001b[36m0.07255\u001b[0m       \u001b[32m0.09129\u001b[0m      0.79476      0.98504  168.51s\n",
      "     17       \u001b[36m0.06542\u001b[0m       \u001b[32m0.08938\u001b[0m      0.73187      0.98527  169.07s\n",
      "     18       \u001b[36m0.06013\u001b[0m       \u001b[32m0.07984\u001b[0m      0.75310      0.98661  168.76s\n",
      "     19       \u001b[36m0.05654\u001b[0m       0.08523      0.66336      0.98527  168.54s\n",
      "     20       \u001b[36m0.05343\u001b[0m       \u001b[32m0.07979\u001b[0m      0.66966      0.98616  169.33s\n",
      "     21       \u001b[36m0.05042\u001b[0m       0.08095      0.62292      0.98542  167.97s\n",
      "     22       \u001b[36m0.04997\u001b[0m       \u001b[32m0.07641\u001b[0m      0.65391      0.98780  168.40s\n",
      "     23       \u001b[36m0.04859\u001b[0m       \u001b[32m0.07367\u001b[0m      0.65956      0.98638  168.74s\n",
      "     24       \u001b[36m0.04747\u001b[0m       0.07656      0.62003      0.98601  168.08s\n",
      "     25       \u001b[36m0.04571\u001b[0m       0.07549      0.60549      0.98705  169.93s\n",
      "     26       0.04583       0.07692      0.59584      0.98542  168.72s\n",
      "     27       \u001b[36m0.04394\u001b[0m       0.07721      0.56909      0.98571  168.23s\n",
      "     28       \u001b[36m0.04221\u001b[0m       0.08301      0.50843      0.98467  168.18s\n",
      "     29       \u001b[36m0.04213\u001b[0m       0.10936      0.38522      0.97679  168.34s\n",
      "     30       0.04297       \u001b[32m0.06917\u001b[0m      0.62118      0.98624  168.92s\n",
      "     31       \u001b[36m0.04055\u001b[0m       0.08733      0.46438      0.98251  168.34s\n",
      "     32       0.04104       0.08560      0.47944      0.98137  168.70s\n",
      "     33       0.04083       0.09327      0.43771      0.98043  169.01s\n",
      "     34       \u001b[36m0.03889\u001b[0m       0.08219      0.47320      0.98385  172.15s\n",
      "     35       0.03937       0.07314      0.53835      0.98571  168.14s\n",
      "     36       0.03941       0.07821      0.50384      0.98430  168.72s\n",
      "     37       \u001b[36m0.03840\u001b[0m       0.08548      0.44925      0.98237  169.01s\n",
      "     38       0.03886       \u001b[32m0.06611\u001b[0m      0.58777      0.98676  169.74s\n",
      "     39       \u001b[36m0.03824\u001b[0m       0.07572      0.50499      0.98519  168.02s\n",
      "     40       \u001b[36m0.03799\u001b[0m       0.06719      0.56536      0.98765  169.42s\n",
      "     41       \u001b[36m0.03714\u001b[0m       0.06645      0.55890      0.98757  170.95s\n",
      "     42       0.03726       0.07109      0.52407      0.98601  169.32s\n",
      "     43       0.03791       0.07190      0.52722      0.98571  168.95s\n",
      "     44       0.03826       \u001b[32m0.06574\u001b[0m      0.58199      0.98839  169.57s\n",
      "     45       \u001b[36m0.03678\u001b[0m       0.06744      0.54541      0.98780  169.70s\n",
      "     46       \u001b[36m0.03631\u001b[0m       0.07134      0.50898      0.98564  172.05s\n",
      "     47       \u001b[36m0.03488\u001b[0m       \u001b[32m0.06424\u001b[0m      0.54300      0.98743  173.94s\n",
      "     48       0.03535       0.06598      0.53576      0.98817  176.38s\n",
      "     49       0.03620       0.07574      0.47791      0.98524  186.15s\n",
      "     50       0.03492       0.06586      0.53013      0.98765  204.37s\n",
      "     51       \u001b[36m0.03416\u001b[0m       0.07074      0.48293      0.98668  222.30s\n",
      "     52       0.03428       \u001b[32m0.06360\u001b[0m      0.53901      0.98810  237.10s\n",
      "     53       0.03483       0.06989      0.49836      0.98810  270.85s\n",
      "     54       0.03419       0.06578      0.51982      0.98795  302.03s\n",
      "     55       \u001b[36m0.03242\u001b[0m       \u001b[32m0.06235\u001b[0m      0.51991      0.98862  286.68s\n",
      "     56       0.03386       0.06615      0.51180      0.98810  281.00s\n",
      "     57       \u001b[36m0.03236\u001b[0m       0.06322      0.51190      0.98847  284.17s\n",
      "     58       \u001b[36m0.03111\u001b[0m       0.06977      0.44592      0.98676  233.29s\n",
      "     59       0.03205       0.06403      0.50045      0.98854  222.16s\n",
      "     60       0.03336       \u001b[32m0.06168\u001b[0m      0.54087      0.98906  204.60s\n",
      "     61       0.03135       \u001b[32m0.06075\u001b[0m      0.51599      0.98966  180.41s\n",
      "     62       \u001b[36m0.03099\u001b[0m       0.06289      0.49272      0.98839  178.24s\n",
      "     63       0.03202       0.06087      0.52598      0.99010  176.74s\n",
      "     64       \u001b[36m0.03043\u001b[0m       0.06192      0.49149      0.98876  173.94s\n",
      "     65       0.03071       0.06326      0.48544      0.98891  173.18s\n",
      "     66       0.03101       0.06156      0.50379      0.98832  173.82s\n",
      "     67       0.03141       0.06192      0.50734      0.98958  173.90s\n",
      "     68       0.03504       0.06827      0.51323      0.98795  171.96s\n",
      "     69       0.03109       0.06364      0.48848      0.98829  172.33s\n",
      "     70       0.03176       0.06923      0.45880      0.98658  173.17s\n",
      "     71       0.03109       0.06229      0.49906      0.98884  172.22s\n",
      "     72       0.03071       0.06245      0.49179      0.98958  175.50s\n",
      "     73       0.03121       0.06391      0.48832      0.98728  174.08s\n",
      "     74       0.03193       0.06588      0.48467      0.98725  173.33s\n",
      "     75       0.03113       0.06393      0.48686      0.98710  173.98s\n",
      "     76       0.03099       0.06177      0.50169      0.98777  174.87s\n",
      "     77       \u001b[36m0.03039\u001b[0m       0.06382      0.47619      0.98772  174.12s\n",
      "     78       \u001b[36m0.03029\u001b[0m       0.06860      0.44157      0.98785  172.93s\n",
      "     79       0.03068       0.06145      0.49921      0.98770  175.49s\n",
      "     80       \u001b[36m0.02979\u001b[0m       0.06950      0.42869      0.98695  181.24s\n",
      "     81       0.03042       0.06379      0.47688      0.98703  177.79s\n",
      "     82       \u001b[36m0.02900\u001b[0m       0.06784      0.42746      0.98740  180.10s\n",
      "     83       0.03030       0.06891      0.43967      0.98658  185.35s\n",
      "     84       0.02975       0.06614      0.44981      0.98859  192.30s\n",
      "     85       0.03060       0.06749      0.45336      0.98688  195.18s\n",
      "     86       0.03106       0.06513      0.47680      0.98837  199.07s\n",
      "     87       0.02977       0.06101      0.48796      0.98837  206.02s\n",
      "     88       0.02907       0.06860      0.42379      0.98658  210.59s\n",
      "     89       0.02916       0.07689      0.37922      0.98428  207.50s\n",
      "     90       0.03009       0.06835      0.44018      0.98695  202.21s\n",
      "     91       0.02968       0.07417      0.40019      0.98562  211.71s\n",
      "     92       \u001b[36m0.02835\u001b[0m       0.07579      0.37402      0.98420  209.67s\n",
      "     93       0.02905       0.06532      0.44473      0.98748  217.66s\n",
      "     94       0.02976       0.07294      0.40798      0.98509  213.26s\n",
      "     95       0.02927       0.06456      0.45341      0.98688  207.53s\n",
      "     96       0.02967       0.06924      0.42845      0.98792  207.62s\n",
      "     97       0.03019       0.06296      0.47941      0.98695  206.44s\n",
      "     98       0.02955       0.06466      0.45698      0.98822  196.42s\n",
      "     99       0.02918       0.06222      0.46895      0.98934  198.18s\n",
      "    100       \u001b[36m0.02821\u001b[0m       \u001b[32m0.06066\u001b[0m      0.46505      0.98904  197.45s\n",
      "    101       \u001b[36m0.02785\u001b[0m       \u001b[32m0.06036\u001b[0m      0.46134      0.98867  198.13s\n",
      "    102       \u001b[36m0.02779\u001b[0m       0.06589      0.42172      0.98641  199.17s\n",
      "    103       0.02783       0.06205      0.44843      0.98874  201.37s\n",
      "    104       \u001b[36m0.02774\u001b[0m       0.06163      0.45013      0.98755  203.65s\n",
      "    105       0.02788       0.06627      0.42066      0.98681  187.20s\n",
      "    106       0.02947       0.06207      0.47478      0.98926  178.38s\n",
      "    107       0.02819       0.06958      0.40513      0.98681  178.74s\n",
      "    108       0.02783       0.06530      0.42623      0.98755  182.99s\n",
      "    109       0.02818       0.06243      0.45140      0.98852  185.99s\n",
      "    110       \u001b[36m0.02738\u001b[0m       0.06806      0.40225      0.98762  190.24s\n",
      "    111       0.02784       0.06734      0.41347      0.98673  191.49s\n",
      "    112       0.02788       0.06336      0.44009      0.98725  194.83s\n",
      "    113       0.02813       0.06488      0.43356      0.98710  195.74s\n",
      "    114       0.02813       \u001b[32m0.05906\u001b[0m      0.47632      0.98986  195.87s\n",
      "    115       0.02805       0.07019      0.39962      0.98562  193.27s\n",
      "    116       \u001b[36m0.02731\u001b[0m       0.06778      0.40285      0.98822  191.68s\n",
      "    117       0.02854       \u001b[32m0.05898\u001b[0m      0.48398      0.98867  190.15s\n",
      "    118       0.02808       0.07166      0.39187      0.98628  187.98s\n",
      "    119       0.02773       0.06272      0.44215      0.98889  187.71s\n",
      "    120       0.02774       0.06910      0.40135      0.98562  187.14s\n",
      "    121       0.02732       0.06967      0.39222      0.98576  188.91s\n",
      "    122       \u001b[36m0.02640\u001b[0m       0.06185      0.42686      0.98800  194.97s\n",
      "    123       0.02737       0.06619      0.41348      0.98703  202.94s\n",
      "    124       0.02719       0.06876      0.39547      0.98792  207.88s\n",
      "    125       0.02693       \u001b[32m0.05883\u001b[0m      0.45775      0.98993  195.79s\n",
      "    126       0.02670       0.06247      0.42732      0.98844  191.13s\n",
      "    127       0.02857       0.05966      0.47879      0.98852  195.99s\n",
      "    128       \u001b[36m0.02621\u001b[0m       0.06885      0.38066      0.98606  196.61s\n",
      "    129       0.02744       0.06386      0.42965      0.98837  194.22s\n",
      "    130       0.02638       \u001b[32m0.05821\u001b[0m      0.45312      0.98926  194.44s\n",
      "    131       \u001b[36m0.02565\u001b[0m       0.06048      0.42405      0.98881  191.47s\n",
      "    132       0.02737       0.06598      0.41475      0.98792  179.59s\n",
      "    133       0.02810       \u001b[32m0.05643\u001b[0m      0.49790      0.98919  176.64s\n",
      "    134       0.02675       \u001b[32m0.05624\u001b[0m      0.47561      0.98971  180.00s\n",
      "    135       0.02714       0.05999      0.45237      0.98844  185.85s\n",
      "    136       0.02661       0.06303      0.42214      0.98911  190.44s\n",
      "    137       0.02669       0.05646      0.47269      0.98948  197.72s\n",
      "    138       \u001b[36m0.02564\u001b[0m       0.06276      0.40849      0.98859  203.18s\n",
      "    139       0.02717       0.05805      0.46800      0.99010  208.13s\n",
      "    140       0.02664       0.05907      0.45099      0.98978  213.19s\n",
      "    141       0.02654       0.05840      0.45442      0.98948  217.87s\n",
      "    142       0.02758       \u001b[32m0.05611\u001b[0m      0.49164      0.99003  224.59s\n",
      "    143       0.02665       0.06239      0.42724      0.98837  229.07s\n",
      "    144       0.02583       0.06060      0.42617      0.98926  218.99s\n",
      "    145       \u001b[36m0.02543\u001b[0m       0.06671      0.38124      0.98725  214.13s\n",
      "    146       0.02642       0.06166      0.42847      0.98824  208.78s\n",
      "    147       0.02668       0.05745      0.46446      0.98996  190.11s\n",
      "    148       0.02595       0.06213      0.41760      0.98881  183.40s\n",
      "    149       0.02666       0.06690      0.39846      0.98792  183.87s\n",
      "    150       0.02831       0.06715      0.42165      0.98748  191.34s\n",
      "    151       0.02729       0.06360      0.42916      0.98837  188.12s\n",
      "    152       0.02646       0.06439      0.41095      0.98792  178.69s\n",
      "    153       0.02738       0.07184      0.38112      0.98524  187.33s\n",
      "    154       0.02560       \u001b[32m0.05581\u001b[0m      0.45870      0.98904  177.10s\n",
      "    155       0.02667       0.06057      0.44039      0.98889  176.56s\n",
      "    156       0.02679       \u001b[32m0.05572\u001b[0m      0.48080      0.99000  182.98s\n",
      "    157       0.02583       0.05883      0.43917      0.98792  191.63s\n",
      "    158       \u001b[36m0.02499\u001b[0m       \u001b[32m0.05449\u001b[0m      0.45870      0.99040  199.65s\n",
      "    159       0.02664       0.05605      0.47530      0.98822  202.02s\n",
      "    160       0.02533       \u001b[32m0.05447\u001b[0m      0.46494      0.98919  207.76s\n",
      "    161       0.02669       0.05572      0.47900      0.98956  209.75s\n",
      "    162       0.02644       \u001b[32m0.05379\u001b[0m      0.49155      0.99045  205.05s\n",
      "    163       0.02500       0.05477      0.45635      0.99062  198.66s\n",
      "    164       0.02566       0.05874      0.43681      0.98978  196.86s\n",
      "    165       0.02520       0.06023      0.41842      0.98966  192.95s\n",
      "    166       0.02718       0.05742      0.47332      0.98919  192.72s\n",
      "    167       0.02667       0.06107      0.43676      0.98881  192.34s\n",
      "    168       0.02694       0.06721      0.40089      0.98814  192.82s\n",
      "    169       0.02542       0.08206      0.30974      0.98316  194.24s\n",
      "    170       0.02640       0.06228      0.42399      0.98748  193.81s\n",
      "    171       0.02519       0.05766      0.43677      0.98956  183.86s\n",
      "    172       0.02562       0.05643      0.45399      0.98829  180.64s\n",
      "    173       0.02598       0.05955      0.43624      0.98966  181.90s\n",
      "    174       0.02521       0.05582      0.45157      0.98973  184.58s\n",
      "    175       \u001b[36m0.02478\u001b[0m       0.05780      0.42877      0.98906  178.27s\n",
      "    176       0.02524       0.05712      0.44194      0.98993  179.10s\n",
      "    177       0.02552       0.05670      0.45008      0.99040  178.18s\n",
      "    178       \u001b[36m0.02462\u001b[0m       0.05918      0.41606      0.98941  174.53s\n",
      "    179       0.02534       0.05704      0.44430      0.99003  177.90s\n",
      "    180       0.02473       0.06077      0.40700      0.98936  177.31s\n",
      "    181       \u001b[36m0.02431\u001b[0m       0.05477      0.44388      0.99055  177.74s\n",
      "    182       0.02454       0.05662      0.43342      0.98963  178.85s\n",
      "    183       0.02498       0.06396      0.39062      0.98785  178.11s\n",
      "    184       0.02529       0.07437      0.34006      0.98576  177.55s\n",
      "    185       0.02551       0.05774      0.44183      0.98934  186.09s\n",
      "    186       0.02469       0.05500      0.44901      0.99025  177.95s\n",
      "    187       0.02485       0.05876      0.42298      0.98859  175.10s\n",
      "    188       0.02441       0.05773      0.42289      0.98904  175.47s\n",
      "    189       \u001b[36m0.02386\u001b[0m       0.05467      0.43637      0.99062  176.97s\n",
      "    190       0.02506       0.05483      0.45706      0.99000  182.59s\n",
      "    191       \u001b[36m0.02374\u001b[0m       0.05774      0.41111      0.98958  189.62s\n",
      "    192       0.02583       0.05413      0.47724      0.98948  198.59s\n",
      "    193       0.02591       0.05706      0.45411      0.99018  208.23s\n",
      "    194       0.02498       0.05634      0.44348      0.99033  214.38s\n",
      "    195       0.02385       0.05684      0.41952      0.98941  222.47s\n",
      "    196       \u001b[36m0.02362\u001b[0m       0.06785      0.34807      0.98681  229.06s\n",
      "    197       0.02451       0.06017      0.40740      0.98934  230.85s\n",
      "    198       0.02453       \u001b[32m0.05239\u001b[0m      0.46830      0.99040  229.61s\n",
      "    199       0.02585       0.05432      0.47589      0.99030  218.42s\n",
      "    200       0.02430       \u001b[32m0.05232\u001b[0m      0.46449      0.99030  207.76s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7f440780b490>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7f440780b390>,\n",
       "     check_input=True, custom_scores=None,\n",
       "     layers=[(<class 'lasagne.layers.input.InputLayer'>, {'shape': (None, 1, 20, 20)}), (<class 'lasagne.layers.conv.Conv2DLayer'>, {'filter_size': 5, 'nonlinearity': <function rectify at 0x7f4408585f50>, 'num_filters': 32}), (<class 'lasagne.layers.pool.MaxPool2DLayer'>, {'pool_size': 2}), (<class 'lasa....layers.dense.DenseLayer'>, {'num_units': 2, 'nonlinearity': <function softmax at 0x7f4408585b90>})],\n",
       "     loss=None, max_epochs=500, more_params={},\n",
       "     objective=<function objective at 0x7f440780ef50>, objective_l2=0.0025,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f440840f050>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7f44078101b8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f4407810200>],\n",
       "     regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7f442bc58910>,\n",
       "     update=<function adam at 0x7f440840fb18>, update_learning_rate=0.0002,\n",
       "     use_label_encoder=False, verbose=2,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = np.arange(np.size(trainY))\n",
    "np.random.shuffle(random_indices)\n",
    "# print trainY[random_indices]\n",
    "net0.fit(trainX[random_indices], trainY[random_indices], epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 6min 23s, total: 8min 18s\n",
      "Wall time: 1min 31s\n",
      "0.997137857768\n"
     ]
    }
   ],
   "source": [
    "%time trainY_predicted = net0.predict(trainX)\n",
    "print sk.metrics.accuracy_score(trainY_predicted, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 s, sys: 2min 44s, total: 3min 33s\n",
      "Wall time: 39.3 s\n"
     ]
    }
   ],
   "source": [
    "%time testY = net0.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testY_frame = pd.DataFrame()\n",
    "testY_frame['Id'] = testIds\n",
    "testY_frame['Prediction'] = testY\n",
    "testY_frame.sort_values(by='Id', inplace=True)\n",
    "testY_frame.to_csv('results/res4.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
