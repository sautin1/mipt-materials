{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts matrix (n, m), representing an image, into a vector (n*m, )\n",
    "def img_to_row(img, index):\n",
    "    data = img.flatten().astype(float)\n",
    "    return data\n",
    "\n",
    "# returns a matrix representing a directory of images (row = image, column = pixel number)\n",
    "def img_dir_to_matrix(root_path, extension = '', need_names = False):\n",
    "    index = 0\n",
    "    data = None\n",
    "    filenames = []\n",
    "    for (path, dirs, files) in os.walk(root_path):\n",
    "        for filename in files:\n",
    "            if (filename.endswith(extension)):\n",
    "                fullpath = os.path.join(path, filename)\n",
    "                img = cv2.imread(fullpath, 0)\n",
    "                row = img_to_row(img, index)\n",
    "                if index == 0:\n",
    "                    data = row.reshape(1, -1)\n",
    "                else:\n",
    "                    data = np.vstack([data, row])\n",
    "                if need_names:\n",
    "                    filenames.append(filename)\n",
    "#                 if index == 5:\n",
    "#                     return (data, filenames) if need_names else data\n",
    "                index += 1\n",
    "                if index % 5000 == 0:\n",
    "                    print index\n",
    "    return (data, filenames) if need_names else data\n",
    "\n",
    "def export_to_csv(path, array, head = None):\n",
    "    frame = pd.DataFrame(array, columns=head)\n",
    "    frame.to_csv(path, sep = ',', header = (head != None), index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_train_class(root_path, extension, class_value):\n",
    "    train = img_dir_to_matrix(root_path, extension)\n",
    "    train_y = np.array([class_value] * train.shape[0])\n",
    "    return (train, train_y)\n",
    "    \n",
    "def generate_train_sample(root_path, extension, class_true_dir, class_false_dir):\n",
    "    if not root_path.endswith('/'):\n",
    "        root_path += '/'\n",
    "    print 'Generating training sample for True class'\n",
    "    train_true, train_true_y = generate_train_class(root_path + class_true_dir, extension, 1)\n",
    "    print 'Generating training sample for False class'\n",
    "    train_false, train_false_y = generate_train_class(root_path + class_false_dir, extension, 0)\n",
    "    \n",
    "    print 'Merging samples'\n",
    "    trainX = np.concatenate((train_true, train_false), 0)\n",
    "    trainY = np.concatenate((train_true_y, train_false_y), 0)\n",
    "    return (trainX, trainY)\n",
    "\n",
    "def generate_test_sample(root_path, extension):\n",
    "    print 'Generating test sample'\n",
    "    if not root_path.endswith('/'):\n",
    "        root_path += '/'\n",
    "    (data, filenames) = img_dir_to_matrix(root_path, extension, need_names=True)\n",
    "    test_ids = np.array([int(filename.split('.')[0]) for filename in filenames])\n",
    "    frame = pd.DataFrame(data)\n",
    "    frame['id'] = test_ids\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training sample for True class\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "Generating training sample for False class\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "Merging samples\n",
      "CPU times: user 10min 54s, sys: 4min 16s, total: 15min 11s\n",
      "Wall time: 15min 13s\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "CPU times: user 3min 54s, sys: 1min 35s, total: 5min 29s\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%time trainX, trainY = generate_train_sample('data/train/', '.tif', 'Hieroglyph', 'Other')\n",
    "%time test_frame = generate_test_sample('data/test/', '.tif')\n",
    "\n",
    "export_to_csv('data/train/trainX.csv', trainX)\n",
    "export_to_csv('data/train/trainY.csv', trainY)\n",
    "test_frame.to_csv('data/test/testX.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 s, sys: 70.7 ms, total: 3.03 s\n",
      "Wall time: 3.03 s\n",
      "CPU times: user 4.66 ms, sys: 108 Âµs, total: 4.77 ms\n",
      "Wall time: 4.62 ms\n",
      "CPU times: user 1.24 s, sys: 27.5 ms, total: 1.27 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%time trainX = pd.read_csv('data/train/trainX.csv', header=None, dtype=np.float32).values.reshape((-1, 1, 20, 20))\n",
    "%time trainY = pd.read_csv('data/train/trainY.csv', header=None, dtype=np.int32).values.reshape((-1))\n",
    "%time test_info = pd.read_csv('data/test/testX.csv')\n",
    "testIds = test_info['id'].values.astype(int)\n",
    "testX = test_info.drop('id', 1).values.astype(np.float32).reshape((-1, 1, 20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building convolutional neural net\n",
    "Architecture taken from:  \n",
    "http://nbviewer.jupyter.org/github/dnouri/nolearn/blob/master/docs/notebooks/CNN_tutorial.ipynb  \n",
    "A good compromise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import lasagne.layers as layers\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.updates import adam\n",
    "\n",
    "from nolearn.lasagne import NeuralNet, TrainSplit, PrintLayerInfo\n",
    "layer_info = PrintLayerInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers0 = [\n",
    "    (layers.InputLayer, {'shape': (None, 1, 20, 20)}),\n",
    "\n",
    "    (layers.Conv2DLayer, {'num_filters': 64, 'filter_size': 5, 'nonlinearity': rectify}),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': 2}),\n",
    "\n",
    "    (layers.Conv2DLayer, {'num_filters': 64, 'filter_size': 5, 'nonlinearity': rectify}),\n",
    "    (layers.MaxPool2DLayer, {'pool_size': 2}),\n",
    "\n",
    "    (layers.DenseLayer, {'num_units': 512, 'nonlinearity': rectify}),\n",
    "    (layers.DropoutLayer, {}),\n",
    "    (layers.DenseLayer, {'num_units': 32, 'nonlinearity': rectify}),\n",
    "\n",
    "    (layers.DenseLayer, {'num_units': 2, 'nonlinearity': softmax}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 252194 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "name        size        total    cap.Y    cap.X    cov.Y    cov.X\n",
      "----------  --------  -------  -------  -------  -------  -------\n",
      "input0      1x20x20       400   100.00   100.00   100.00   100.00\n",
      "conv2d1     64x16x16    16384   100.00   100.00    25.00    25.00\n",
      "maxpool2d2  64x8x8       4096   100.00   100.00    25.00    25.00\n",
      "conv2d3     64x4x4       1024    76.92    76.92    65.00    65.00\n",
      "maxpool2d4  64x2x2        256    76.92    76.92    65.00    65.00\n",
      "dense5      512           512   100.00   100.00   100.00   100.00\n",
      "dropout6    512           512   100.00   100.00   100.00   100.00\n",
      "dense7      32             32   100.00   100.00   100.00   100.00\n",
      "dense8      2               2   100.00   100.00   100.00   100.00\n",
      "\n",
      "Explanation\n",
      "    X, Y:    image dimensions\n",
      "    cap.:    learning capacity\n",
      "    cov.:    coverage of image\n",
      "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
      "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
      "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net0 = NeuralNet(\n",
    "    layers = layers0,\n",
    "    max_epochs = 100,\n",
    "    update = adam,\n",
    "    update_learning_rate = 0.01,\n",
    "    objective_l2 = 0.0025,\n",
    "    train_split = TrainSplit(eval_size=0.16),\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "net0.initialize()\n",
    "layer_info(net0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 252194 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "name        size        total    cap.Y    cap.X    cov.Y    cov.X\n",
      "----------  --------  -------  -------  -------  -------  -------\n",
      "input0      1x20x20       400   100.00   100.00   100.00   100.00\n",
      "conv2d1     64x16x16    16384   100.00   100.00    25.00    25.00\n",
      "maxpool2d2  64x8x8       4096   100.00   100.00    25.00    25.00\n",
      "conv2d3     64x4x4       1024    76.92    76.92    65.00    65.00\n",
      "maxpool2d4  64x2x2        256    76.92    76.92    65.00    65.00\n",
      "dense5      512           512   100.00   100.00   100.00   100.00\n",
      "dropout6    512           512   100.00   100.00   100.00   100.00\n",
      "dense7      32             32   100.00   100.00   100.00   100.00\n",
      "dense8      2               2   100.00   100.00   100.00   100.00\n",
      "\n",
      "Explanation\n",
      "    X, Y:    image dimensions\n",
      "    cap.:    learning capacity\n",
      "    cov.:    coverage of image\n",
      "    \u001b[35mmagenta\u001b[0m: capacity too low (<1/6)\n",
      "    \u001b[36mcyan\u001b[0m:    image coverage too high (>100%)\n",
      "    \u001b[31mred\u001b[0m:     capacity too low and coverage too high\n",
      "\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -------\n",
      "      1       \u001b[36m2.34756\u001b[0m       \u001b[32m0.82878\u001b[0m      2.83255      0.92676  545.19s\n",
      "      2       \u001b[36m0.56803\u001b[0m       \u001b[32m0.50722\u001b[0m      1.11988      0.94000  542.60s\n",
      "      3       \u001b[36m0.38729\u001b[0m       \u001b[32m0.37145\u001b[0m      1.04265      0.94990  549.76s\n",
      "      4       \u001b[36m0.28620\u001b[0m       \u001b[32m0.32819\u001b[0m      0.87203      0.94782  538.63s\n",
      "      5       \u001b[36m0.23226\u001b[0m       \u001b[32m0.29130\u001b[0m      0.79734      0.94774  511.00s\n",
      "      6       \u001b[36m0.19183\u001b[0m       \u001b[32m0.21704\u001b[0m      0.88382      0.95382  537.71s\n",
      "      7       \u001b[36m0.16630\u001b[0m       \u001b[32m0.15745\u001b[0m      1.05624      0.96922  496.20s\n",
      "      8       \u001b[36m0.15746\u001b[0m       0.16971      0.92779      0.96411  486.00s\n",
      "      9       \u001b[36m0.14996\u001b[0m       0.18132      0.82705      0.96882  489.62s\n",
      "     10       \u001b[36m0.14284\u001b[0m       \u001b[32m0.15566\u001b[0m      0.91761      0.96496  506.70s\n",
      "     11       \u001b[36m0.13946\u001b[0m       \u001b[32m0.12739\u001b[0m      1.09476      0.97073  541.91s\n",
      "     12       \u001b[36m0.13881\u001b[0m       0.17435      0.79617      0.96453  541.04s\n",
      "     13       0.17237       0.22209      0.77613      0.94700  523.26s\n",
      "     14       0.15128       0.23228      0.65128      0.94613  503.02s\n",
      "     15       \u001b[36m0.13736\u001b[0m       0.16711      0.82198      0.96027  552.60s\n",
      "     16       \u001b[36m0.13310\u001b[0m       0.14231      0.93526      0.96545  501.39s\n",
      "     17       0.13963       \u001b[32m0.12506\u001b[0m      1.11644      0.97378  495.58s\n",
      "     18       0.13881       0.15529      0.89384      0.95826  500.26s\n",
      "     19       0.14315       0.15920      0.89919      0.96071  502.90s\n",
      "     20       0.14482       \u001b[32m0.12296\u001b[0m      1.17775      0.97123  497.81s\n",
      "     21       0.15997       0.13171      1.21459      0.97349  526.10s\n",
      "     22       0.14726       \u001b[32m0.11370\u001b[0m      1.29519      0.97326  506.07s\n",
      "     23       0.14340       0.12590      1.13899      0.97200  512.74s\n",
      "     24       0.16420       0.15585      1.05360      0.96887  524.96s\n",
      "     25       0.14165       0.13947      1.01557      0.96853  487.14s\n",
      "     26       0.15431       0.15792      0.97714      0.96796  513.33s\n",
      "     27       0.15766       0.15561      1.01314      0.96808  516.83s\n",
      "     28       0.14852       0.14956      0.99304      0.96225  527.99s\n",
      "     29       0.14766       0.15245      0.96858      0.97133  536.65s\n",
      "     30       0.14995       0.12214      1.22768      0.97594  502.83s\n",
      "     31       0.14839       0.28569      0.51942      0.91721  488.49s\n",
      "     32       0.15043       0.14695      1.02374      0.96131  485.50s\n",
      "     33       0.13344       0.15698      0.85004      0.95618  483.72s\n",
      "     34       0.13998       0.22422      0.62428      0.95523  486.41s\n",
      "     35       0.15488       0.15462      1.00174      0.96131  497.59s\n",
      "     36       0.18358       0.15065      1.21861      0.96302  495.33s\n",
      "     37       0.20315       0.24877      0.81662      0.95719  498.44s\n",
      "     38       0.20597       0.21631      0.95220      0.94529  500.06s\n",
      "     39       0.35548       0.21145      1.68116      0.95955  499.84s\n",
      "     40       0.16830       0.14550      1.15674      0.97081  499.30s\n",
      "     41       0.22463       0.32078      0.70026      0.95846  502.22s\n",
      "     42       0.21981       0.14711      1.49414      0.97170  501.69s\n",
      "     43       0.18218       0.15099      1.20659      0.96622  499.81s\n",
      "     44       0.16765       0.14633      1.14570      0.96595  505.14s\n",
      "     45       0.18175       0.16982      1.07026      0.96483  508.32s\n",
      "     46       0.28075       0.21298      1.31819      0.95645  505.98s\n",
      "     47       0.21005       0.16130      1.30225      0.96999  506.34s\n",
      "     48       0.17470       0.15575      1.12169      0.96855  515.07s\n",
      "     49       0.20494       0.20322      1.00843      0.96052  516.72s\n",
      "     50       0.21712       0.21920      0.99048      0.95097  511.87s\n",
      "     51       0.17595       0.16726      1.05191      0.96106  520.67s\n",
      "     52       0.18426       0.13963      1.31965      0.97123  542.76s\n",
      "     53       0.16907       0.18740      0.90218      0.95702  598.47s\n",
      "     54       0.19836       0.14761      1.34378      0.96977  680.93s\n",
      "     55       0.17842       0.22997      0.77584      0.95131  697.51s\n",
      "     56       0.15246       0.12141      1.25571      0.96791  692.26s\n",
      "     57       0.15938       0.28549      0.55827      0.93934  661.49s\n",
      "     58       0.29032       0.43834      0.66233      0.93849  585.61s\n",
      "     59       1.71976       1.55606      1.10520      0.49742  506.97s\n",
      "     60       1.34383       1.20810      1.11234      0.83006  491.33s\n",
      "     61       1.71507       1.26789      1.35270      0.62979  499.65s\n",
      "     62       1.18831       1.09282      1.08738      0.57738  509.13s\n",
      "     63       1.01908       0.94954      1.07323      0.57738  516.54s\n",
      "     64       0.89838       0.85397      1.05200      0.57738  516.85s\n",
      "     65       0.80118       0.56447      1.41934      0.91225  521.12s\n",
      "     66       0.44449       0.33589      1.32332      0.94772  522.76s\n",
      "     67       0.32122       0.24563      1.30775      0.96158  499.01s\n",
      "     68       0.26489       0.29924      0.88521      0.94745  488.04s\n",
      "     69       0.22667       0.18233      1.24322      0.96657  476.25s\n",
      "     70       0.19320       0.18976      1.01809      0.96783  487.02s\n",
      "     71       0.18106       0.16762      1.08018      0.96200  489.75s\n",
      "     72       0.17671       0.18812      0.93939      0.95689  497.56s\n",
      "     73       0.17751       0.15852      1.11974      0.96808  502.50s\n",
      "     74       0.16180       0.14155      1.14305      0.96964  493.44s\n",
      "     75       0.17513       0.16762      1.04477      0.96352  490.40s\n",
      "     76       0.16856       0.13246      1.27256      0.96892  495.81s\n",
      "     77       0.18056       0.15317      1.17889      0.96910  504.34s\n",
      "     78       0.16690       0.15019      1.11119      0.96753  504.71s\n",
      "     79       0.16477       0.14805      1.11295      0.96528  503.62s\n",
      "     80       0.17692       0.26120      0.67735      0.94958  522.21s\n",
      "     81       0.18234       0.17662      1.03237      0.96009  541.11s\n",
      "     82       0.17448       0.16738      1.04241      0.96481  537.07s\n",
      "     83       0.17712       0.16112      1.09926      0.96617  546.41s\n",
      "     84       0.15289       0.14908      1.02558      0.96064  553.59s\n",
      "     85       0.15913       0.15470      1.02865      0.96327  545.77s\n",
      "     86       0.16003       0.16076      0.99546      0.96310  526.38s\n",
      "     87       0.16457       0.15483      1.06290      0.96625  507.82s\n",
      "     88       0.17544       0.15725      1.11567      0.95818  514.45s\n",
      "     89       0.17840       0.26018      0.68566      0.92272  525.08s\n",
      "     90       0.18086       0.21459      0.84283      0.94762  539.61s\n",
      "     91       0.17527       0.15209      1.15240      0.96178  558.33s\n",
      "     92       0.16371       0.15112      1.08325      0.96528  563.51s\n",
      "     93       0.15792       0.14212      1.11116      0.96644  560.76s\n",
      "     94       0.16853       0.20109      0.83809      0.94722  547.95s\n",
      "     95       0.16767       0.15389      1.08951      0.96461  536.05s\n",
      "     96       0.15633       0.15963      0.97934      0.95325  532.73s\n",
      "     97       0.17897       0.14302      1.25132      0.97036  543.41s\n",
      "     98       0.15699       0.12589      1.24704      0.96538  552.66s\n",
      "     99       0.14857       0.16668      0.89131      0.95744  556.55s\n",
      "    100       0.16670       0.20806      0.80125      0.94963  558.43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7f521ad683d0>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7f521ad682d0>,\n",
       "     check_input=True, custom_scores=None,\n",
       "     layers=[(<class 'lasagne.layers.input.InputLayer'>, {'shape': (None, 1, 20, 20)}), (<class 'lasagne.layers.conv.Conv2DLayer'>, {'filter_size': 5, 'nonlinearity': <function rectify at 0x7f521badef50>, 'num_filters': 64}), (<class 'lasagne.layers.pool.MaxPool2DLayer'>, {'pool_size': 2}), (<class 'lasa....layers.dense.DenseLayer'>, {'num_units': 2, 'nonlinearity': <function softmax at 0x7f521badeb90>})],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<function objective at 0x7f521ad67f50>, objective_l2=0.0025,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x7f521b968050>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7f51fc1819e0>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f51fc181ab8>],\n",
       "     regression=False,\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7f51fc1f2b90>,\n",
       "     update=<function adam at 0x7f521b968b18>, update_learning_rate=0.01,\n",
       "     use_label_encoder=False, verbose=2,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indices = np.arange(np.size(trainY))\n",
    "np.random.shuffle(random_indices)\n",
    "# print trainY[random_indices]\n",
    "net0.fit(trainX[random_indices], trainY[random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 8s, sys: 6min 21s, total: 10min 30s\n",
      "Wall time: 3min 43s\n",
      "0.949818772653\n"
     ]
    }
   ],
   "source": [
    "%time trainY_predicted = net0.predict(trainX)\n",
    "print sk.metrics.accuracy_score(trainY_predicted, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 2min 44s, total: 4min 30s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%time testY = net0.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testY_frame = pd.DataFrame()\n",
    "testY_frame['Id'] = testIds\n",
    "testY_frame['Prediction'] = testY\n",
    "testY_frame.sort_values(by='Id', inplace=True)\n",
    "testY_frame.to_csv('results/res3.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
