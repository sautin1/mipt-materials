{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 1**: Зачем нужно структурное предсказание?\n",
    "\n",
    "В задачах классификации и регрессии для каждого объекта предсказывается дискретная или непрерывная переменная (метка класса или число).\n",
    "Структурное предсказание используется для предсказания сложных систем переменных, связанных между собой, например, последовательности переменных и т.д.. Пример задачи, в которой это может понадобиться, --- расставление тегов для неких объектов (одному объекту может соответствовать несколько тегов).\n",
    "\n",
    "**Вопрос 2**: Что такое сопряженное распределение?\n",
    "\n",
    "Распределение (априорное) $p(\\theta)\\sim \\mathbb A(\\alpha)$ и функция правдоподобия $p(x|\\theta)\\sim \\mathbb B(\\beta)$ называются сопряженными, если распределение (апостериорное) $p(\\theta | x) \\sim \\mathbb A(\\gamma)$.\n",
    "\n",
    "**Вопрос 3**: Какое распределение сопряженное к равномерному, докажите?\n",
    "\n",
    "Нашел такую теорему:  \n",
    "пусть $\\{X_k\\}_{k=1}^{n}$ --- выборка из равномерного распределения на интервале $(0, W)$, значение $W$ неизвестно. Предположим, что априорное распределение $W$ --- это распределение Парето с параметрами $w_0>0$ и $\\alpha>0$. Тогда апостериорное распределение $W$ при $X_i = x_i$ есть распределение Парето с параметрами $max(w_0, x_1, ..., x_n)$ и $\\alpha + n$.  \n",
    "\n",
    "Доказывать не умею.\n",
    "\n",
    "**Вопрос 4**: В чем заключается Байесовский подход к машинному обучению?\n",
    "\n",
    "В интерпретации задачи машинного обучения как восстановления зависимости между наблюдаемыми и скрытыми компонентами, которая восстанавливается по обучающей выборке. Моделью этой зависимости являются совместные вероятностные распределения над наблюдаемыми, скрытыми компонентами и над параметрами, которые устанавливаются в ходе обучения.\n",
    "\n",
    "**Вопрос 5**: В чем основные преимущества Байесовского подхода к машинному обучения?\n",
    "\n",
    "У байесовского подхода к машинному обучению есть несколько основных преимуществ:\n",
    "1) можно строить достаточно сложные вероятностные модели на основе более простых. Это достигается за счет того, что байесовский вывод одной модели мы воспринимаем как априорное распределение в следующей вероятностной модели.\n",
    "2) Низкий шанс переобучения. В байесовском подходе используется априорное распределение, благодаря чему есть возможность регуляризовывать модель машинного обучения.\n",
    "3) Возможность работы с обучающими выборками, в которых не на всех объектах известен ответ (частично размеченная обучающая выборка).\n",
    "\n",
    "**Вопрос 6**: Чем отличается структурный метод опорных векторов от неструктурного, в чем сложности при обучении структурного?\n",
    "\n",
    "В структурном методе предполагается, что присутствует зависимость между объектами. Пусть $X$ --- наблюдаемые объекты, а $T$ --- дискретные скрытые переменные (известные для объектов обучающей выборки). В структурном SVM вводится параметрическая модель $E(X,T,W)$, рассматриваемая как линейная функция от весов $W$. Затем решается следующая задача оптимизации:  \n",
    "$\\frac {1}{2} ||W||^2  + C\\xi\\rightarrow \\min_{W, \\xi}$  \n",
    "$E(X, T, W) \\ge E(X, \\hat T, W) + \\Delta (T, \\hat T) - \\xi$, $\\forall \\hat T$, $\\xi \\ge 0$.  \n",
    "\n",
    "При этом, проблемой является то, что последнее условие представляет из себя экспоненциальное число неравенств, в связи с чем задачу не всегда удается решить за полиномиальное время."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Task</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу построения коллажа из нескольких изображений, к примеру несколько фотографий группы людей, на каждой кто-то отвернулся или моргнул ... Вы хотите получить одну фотографию, на которой все получились хорошо. На вход поступает K изображений а на выходе вам нужно выдать матрицу размером с изображение, где в каждом пикселе будет указано из какой картинки вам нужно его взять. Вы хотите сделать фотографию так, чтобы места склейки были незаметны. \n",
    "\n",
    "- Введите граф модель, почему вы выбрали именно такую, приложите рисунок\n",
    "- Потенциалы каких порядков вы собираетесь использовать? \n",
    "- Определите потенциалы -- какой в них физический смысл? почему они поощряют незаметные склеивания?\n",
    "- Предложить несколько вариантов выбора потенциалов.\n",
    "\n",
    "![](ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Графическая модель__. Вообще для сегментации изображений в случае не очень больших картинок нередко используют fully-connected модели (как описано [здесь](http://vladlen.info/papers/densecrf.pdf)):  \n",
    "![Fully connected](crf-dense.png)\n",
    "\n",
    "Здесь же я бы использовал обычную решетку:\n",
    "![Grid](crf-grid.jpg)\n",
    "\n",
    "Выбор пал на эту графическую модель по двум причинам:  \n",
    "    1) нас интересует схожесть именно рядом стоящих пикселей (хотим гладкие границы, незаметные места склейки);  \n",
    "    2) хотим делать короткие разрезы;  \n",
    "    3) картинки большого размера, использование fully-connected модели вычислительно сложно.\n",
    "\n",
    "__Порядки потенциалов__. Не понимаю, что меня ограничивает от выбора потенциалов любого порядка.  \n",
    "\n",
    "__Потенциалы__. Унарные потенциалы надо выбрать так, чтобы они показывали, из какого изображения надо брать некоторые пиксели. Парные же потенциалы нужно выбирать так, чтобы они поддерживали:\n",
    "    * создание разреза в месте, где изображения из исходной серии хорошо соответствуют друг другу;  \n",
    "    * короткие разрезы. При выборе решетки в качестве графической модели этот пункт не имеет значения, т.к. длины всех разрезов одинаковы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Bonus part: Semantic Image Segmentation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Если вы, хотите разобраться с граф моделями -- попробуйте реализовать это на питон, выполнение займет около 30-40 часов, на щедрые бонусные баллы (3-5 баллов) -- можно обсудить заранее. Если решитесь, напишите мне. \n",
    "\n",
    "http://www.machinelearning.ru/wiki/index.php?title=Графические_модели_(курс_лекций)/2012/Задание_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
