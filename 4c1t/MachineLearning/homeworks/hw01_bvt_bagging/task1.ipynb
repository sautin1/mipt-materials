{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU\n",
    "    - 2.9 Model Selection and the Bias–Variance Tradeoff \n",
    "    - 15 Random Forests\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ\n",
    "- Andrew Ng, Bias vs. Variance, https://goo.gl/1ISZ6Y\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall <номер_группы> <фамилия>``, к примеру -- ``ML2016_fall 401 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb``, к примеру -- ``ivanov_401_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Мы используем автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Напоминаем, что дедлайны жесткие, письма пришедшие после автоматически удаляются =( чтобы соблазна не было "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "__Возможно ответы на некоторые вопросы не будут полностью соответствовать теории с лекций/семинаров, т.к. я готовился по теории в онлайн-курсе от МФТИ и Яндекса на Coursera__\n",
    "\n",
    "**Вопрос 1**: Какие формулы у шума, смещения, разброса? Какой смысл у этих компонент?\n",
    "\n",
    "Ошибку, которая возникает при применении алгоритма к новым данным, можно разложить на 3 компоненты: шум, смещение и разброс. В случае среднеквадратичной ошибки ($y(x)$ --- истинный ответ на объекте $x$, $a(x)$ --- предсказание алгоритма на объекте $x$):  \n",
    "<font color='blue'>\n",
    "$\\mathbb E((y(x) - a(x))^2) = \\mathbb E(y(x)^2 - 2\\cdot y(x)\\cdot a(x) + a(x)^2) = $\n",
    "$\\mathbb E(a(x)^2) + \\mathbb E(y(x)^2) - 2\\mathbb E(a(x)\\cdot y(x)) = $\n",
    "$(\\mathbb E(a(x)^2) - \\mathbb E^2(a(x)) + \\mathbb E^2(a(x))) + (\\mathbb E(y(x)^2) - \\mathbb E^2(y(x)) + \\mathbb E^2(y(x))) - 2\\mathbb E(a(x)y(x)) = $\n",
    "$ \\mathbb D(a(x)) + \\mathbb D(y(x)) + \\mathbb E^2(a(x)) + \\mathbb E^2(y(x)) - 2\\mathbb E(a(x))\\mathbb E(y(x))) = $\n",
    "$ \\mathbb D(a(x)) + \\mathbb D(y(x)) + (\\mathbb E(a(x)) - \\mathbb E(y(x)))^2 = $\n",
    "$ \\mathbb D(a(x)) + \\mathbb D(y(x)) + \\mathbb E^2(a(x) - y(x))$\n",
    "</font>\n",
    "\n",
    "\n",
    "_Шум_. Данные в задаче могут быть зашумлены настолько, что на них в принципе невозможно получить нулевую ошибку и что даже идеальная модель будет ошибаться на новых данных. Шум показывает, _насколько_ сильно идеальная модель ошибается на этой задаче. При этом шум невозможно улучшить, т.к. это характеристика самих данных.  \n",
    "Формула: $\\mathbb D(y(x))$.\n",
    "\n",
    "Далее рассмотрим набор алгоритмов $\\{a_i(x)\\}_{i=1}^{n}$, построенных на основе разных поднаборов одного и того же набора данных (воспринимаем исходную обучающую выборку как случайную величину с некоторым распределением и генерируем серию выборок из одного и того же распределения). Пусть $\\hat{a}(x)$ --- алгоритм, возвращающий для каждого объекта $x$ среднее значение предсказаний алгоритмов $a_i(x)$, а $a_{*}(x)$ --- идеальный алгоритм, решающий нашу задачу.\n",
    "\n",
    "_Смещение_. По сути, это среднее отклонение предсказаний \"среднего\" алгоритма $\\hat{a}(x)$ от предсказаний идеального алгоритма $a_*(x)$. Показывает, достаточно ли сложно выбранное семейство алгоритмов, чтобы приблизить реальную зависимость.  \n",
    "Формула: $\\mathbb E(a(x) - y(x))$.\n",
    "\n",
    "_Разброс_. По сути, это дисперсия предсказаний алгоритмов $\\{a_i(x)\\}_{i=1}^{n}$. Показывает, насколько сильно алгоритм зависит от небольших изменений обучающей выборки.  \n",
    "Формула: $\\mathbb D(a(x))$.\n",
    "\n",
    "**Вопрос 2**: Приведите пример семейства с маленьким смещением и большим разбросом. Приведите пример семейства с большим смещением и маленьким разбросом.\n",
    "\n",
    "_Решающие деревья_ --- пример семейства моделей с низким смещением и большим разбросом. Это семейство достаточно сложно, чтобы восстанавливать непростые зависимости, но при этом малейшее изменение обучающей выборки ведет к построению другого дерева.\n",
    "\n",
    "_Линейные алгоритмы_ --- пример семейства моделей с большим смещением и малым разбросом. Это семейство весьма просто и (по умолчанию, т.е. без применения спрямляющих пространств) не в состоянии восстанавливать сложные (нелинейные) зависимости. Однако при этом малые изменения обучающей выборки практически не влияют на итоговую модель.\n",
    "\n",
    "**Вопрос 3**: Как сгенерировать подвыборку с помощью бутстрапа?\n",
    "\n",
    "Пусть исходная выборка выглядит так: $X=\\{x_i\\}_{i=1}^{l}$.\n",
    "Тогда метод bootstrap строит подвыборку размера $l$ (того же, что и исходная выборка), путем последовательного выбора с возвращением случайного объекта исходной выборки. Таким образом, в bootstrap-выборку некоторые объекты исходной выборки могут попасть несколько раз, а некоторые, в таком случае, не попадут вовсе. \n",
    "\n",
    "**Вопрос 4**: Что такое бэггинг?\n",
    "\n",
    "Подход, который используется при обучении базовых алгоритмов в построении какой-то композиции. Он заключается в том, что каждый базовый алгоритм обучается не на всей исходной выборке, а на неком наборе ее объектов, полученном путем последовательного выбора с возвращением случайного объекта исходной выборки. Размер подвыборки --- это гиперпараметр. Цель применения бэггинга --- понизить корреляцию между базовыми алгоритмами (сделать их максимально независимыми), т.к. чем более независимы базовые алгоритмы, тем сильнее понижается разброс у их композиции (например, у усреднения базовых алгоритмов), а значит и суммарная ошибка алгоритма на новых данных оказывается меньше.\n",
    "\n",
    "**Вопрос 5**:  Как соотносятся смещение и разброс композиции, построенной с помощью бэггинга, со смещением и разбросом одного базового алгоритма?\n",
    "\n",
    "В моем ответе предполагается, что композиция --- это усреднение базовых алгоритмов.\n",
    "Бэггинг понижает корреляцию между базовыми алгоритмами за счет рандомизации обучающей выборки.\n",
    "Смещение базового алгоритма и смещение композиции совпадают, исходя из общего смысла смещения, данного в ответе на вопрос 1. А вот разброс при усреднении независимых алгоритмов, в свою очередь, уменьшается в N раз, где N --- количество базовых алгоритмов: $\\newcommand{\\cov}{\\operatorname{cov}} \\mathbb D(a(x)) = \\mathbb D(\\frac {1}{N} \\sum\\limits_{i = 1}^N a_i(x)) = \\sum\\limits_{i=1}^N \\frac {1}{N^2} \\mathbb D(a_i(x)) + 2\\sum\\limits_{1\\le i < j \\le N} \\frac{1}{N^2}\\cdot \\cov(a_i, a_j) = $  \n",
    "/фиксируем $k\\in \\{1, ..., N\\}$/ $ = \\sum\\limits_{i=1}^N \\frac {1}{N^2} \\mathbb D(a_k(x)) + 2\\sum\\limits_{1\\le i < j \\le N} \\frac{1}{N^2}\\cdot \\cov(a_i, a_j) = $\n",
    "$ \\frac {1}{N} \\mathbb D(a_k(x)) + 2\\sum\\limits_{1\\le i < j \\le N} \\frac{1}{N^2}\\cdot \\cov(a_i, a_j) $.\n",
    "\n",
    "Из полученной формулы видно, что если алгоритмы $\\{a_i\\}_{i=1}^N$ будут независимыми, то $\\forall i, j:\\ i\\ne j: cov(a_i, a_j) = 0$, и разброс уменьшается в $N$ раз.\n",
    "\n",
    "**Вопрос 6**: Как обучается случайный лес? В чем отличия от обычной процедуры построения решающих деревьев?\n",
    "\n",
    "Случайный лес является композицией базовых алгоритмов --- решающих деревьев, поэтому его обучение сводится к обучению каждого из решающих деревьев на выборке, полученной методом bootstrap из исходной, и их последующему усреднению. Сам процесс построения базового алгоритма рандомизирован:\n",
    "- пусть в вершину $k$ пришла выборка $X_k$, хотим разбить эту вершину на две и запустить процесс для каждого из двух новых поддеревьев (продолжаем процесс, пока не выполнится критерий останова);\n",
    "- $Q(X_k, j, t)$ --- критерий ошибки условия $[x^j \\le t]$;\n",
    "- хотим найти наилучшие (с точки зрения минимизации $Q$) параметры разбиения $j$ (индекс признака, по которому разбиваем) и $t$ (пороговое значение признака);\n",
    "- ищем $t$ среди всех возможных порогов, как и раньше;\n",
    "- а вот $j$ будем выбирать не из всех признаков, а из некоторого их поднабора длины $q$.\n",
    "\n",
    "Таким образом, отличие заключается в том, что при построении случайного леса в выборе оптимального разбиения вершины используется случайный поднабор _признаков_ размера $q$. Этот поднабор фиксируется не для всего дерева (как в методе случайных подпространств), а для каждой вершины генерируется заново. Тем самым базовые деревья получаются более независимыми, чем в методе случайных подпространств. Размер поднабора $q$ --- гиперпараметр, который нередко полагают равным $\\sqrt d$ в задачах классификации и равным $\\frac {d}{3}$ --- в задачах регрессии (где $d$ --- количество признаков).\n",
    "\n",
    "**Вопрос 7**: Почему хорошими базовыми алгоритмами для бэггинга являются именно деревья?\n",
    "\n",
    "Потому что у решающих деревьев низкое смещение, они способны восстанавливать достаточно сложные зависимости. Их существенный минус - это большой разброс, но именно бэггинг помогает справиться с этим минусом. В итоге, видим, что совместное использование бэггинга и решающих деревьев теоретически должно быть удачным.\n",
    "\n",
    "**Вопрос 8**: Как оценить качество случайного леса с помощью out-of-bag-процедуры?\n",
    "\n",
    "При построении случайного леса каждый базовый алгоритм обучается на случайной подвыборке, получаемой по методу bootstrap на основе исходной обучающей выборки $X$ (размера $l$). Тем самым, можно заметить, что в большинстве случаев для каждого объекта $x_i$ найдется набор деревьев, в обучающей выборке которых не было объекта $x_i$. Но тогда можно оценивать качество случайного леса на объекте $x_i$, не выделяя часть объектов в тестовую выборку.\n",
    "Пусть случайный лес строится как композиция $N$ базовых алгоритмов, которые обучались на выборках $\\{X_i\\}_{i=1}^N$. Тогда качество (ошибку) алгоритма можно оценить так:\n",
    "$\\sum\\limits_{i = 1}^l Q(y(x_i), \\frac{1}{\\sum\\limits_{n=1}^N [x_i \\notin X_n]}\\cdot \\sum\\limits_{n=1}^N [x_i\\notin X_n]\\cdot b_n(x_i))$, т.е. суммируем функцию потерь по всем объектам, подавая на вход функции потерь правильный ответ $y(x_i)$ и среднее значение прогнозов на объекте $x_i$ тех базовых алгоритмов, которые не обучались на объекте $x_i$.\n",
    "\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Bagging</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Известно, что бэггинг плохо работает, если в качестве базовых классификаторов взять knn. Попробуем понять причины на простом примере.\n",
    "\n",
    "Пусть дана выборка $X^l$ из $l$ объектов с ответами из множества $Y = \\{−1, +1\\}$. Будем рассматривать классификатор одного ближайшего соседа в качестве базового алгоритма. Построим с помощью бэггинга композицию длины $N$:\n",
    "\n",
    "$$a_N(x) = sign(\\sum_{n=1}^{N} b_n(x))$$\n",
    "\n",
    "Оцените вероятность того, что ответ композиции на произвольном объекте x будет\n",
    "отличаться от ответа одного классификатора ближайшего соседа, обученного по всей\n",
    "выборке. Покажите, что эта вероятность стремится к нулю при N → ∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Зафиксируем объект $x$ и его ближайшего соседа $y$. При бутстрапе в каждой выборке используются ~63.2% объектов исходной выборки. Чтобы ответ композиции отличался от метки класса объекта $y$, необходимо чтобы $x$ попал в обучающие выборки менее чем половины деревьев.  \n",
    "$P(x$ попал в $X_i) \\approx 0.632$.\n",
    "Тогда $P($ ответ композиции отличается от ответа 1NN $) = P(x$ попал в менее чем половину выборок $ \\le (1-0.632)^\\frac{N}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bagging Implementation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте беггинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from scipy import stats\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "class BaggingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, n_estimators, items_rate=1.0, features_rate=1.0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: sklearn.Classifier\n",
    "            Базовый алгоритм, который можно обучить (есть метод fit).\n",
    "            Для обучение композиции нужно много таких, можэно получить с помощю copy.deepcopy\n",
    "\n",
    "        n_estimators: int\n",
    "            Число алгоритмов в композиции\n",
    "\n",
    "        items_rate: float > 0\n",
    "            Доля объектов из трейна, на которой будет обучаться каждый базовый алгоритм\n",
    "\n",
    "        features_rate: float > 0\n",
    "            Доля фичей, на которой будет обучаться и применяться каждый базовый алгоритм\n",
    "        \"\"\"\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.items_rate = items_rate\n",
    "        self.features_rate = features_rate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Метод должен обучить композицию алгоритмов, используя X, y как обучающую выборку.\n",
    "        Не забудте реализорвать функционал выбора случайных объектов и фичей.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array\n",
    "        y: 1d np.array\n",
    "        \"\"\"\n",
    "\n",
    "        # Тут храните обеченные базовые алгоритмы\n",
    "        self.estimators = []\n",
    "\n",
    "        # Тут храните фичи для каждого алгоритма\n",
    "        self.features_idx = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            estimator = deepcopy(self.base_estimator)\n",
    "            # =======================================\n",
    "            # Обучите базовые алгоритмы\n",
    "            # =======================================\n",
    "            \n",
    "            # generating training sample (object can be repeated, features cannot be repeated)\n",
    "            objects_cnt, features_cnt = X.shape\n",
    "            train_objects_cnt = max(int(self.items_rate * objects_cnt), 1)\n",
    "            train_features_cnt = max(int(self.features_rate * features_cnt), 1)\n",
    "            objects_idx = np.random.randint(0, high=objects_cnt, size=train_objects_cnt)\n",
    "            features_idx = np.sort(np.random.permutation(np.arange(features_cnt))[:train_features_cnt])\n",
    "            self.features_idx.append(features_idx)\n",
    "            X_train = X[objects_idx, :][:, features_idx]\n",
    "            y_train = y[objects_idx]\n",
    "\n",
    "            # training base estimator\n",
    "            estimator.fit(X_train, y_train)\n",
    "            self.estimators.append(estimator)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array матрица объекты признаки на которых нужно сказать ответ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: 1d np.array, Вектор классов для каждого объекта\n",
    "        \"\"\"\n",
    "        # Ввиду того, что автор задания сам не определился с тем, вектор чего (вероятностей или меток классов) \n",
    "        # я все-таки должен возвращать, я буду возвращать вектор меток классов.\n",
    "        \n",
    "        predictions = [] # Храните тут ответы каждого базового алгоритма \n",
    "        \n",
    "        for estimator, features_idx in zip(self.estimators, self.features_idx):\n",
    "            # =======================================\n",
    "            # Получите ответы (метки классов) от всех базовых алгоритмов\n",
    "            # ======================================\n",
    "            predictions.append(estimator.predict(X[:, features_idx]))\n",
    "        # =======================================\n",
    "        # Усредните предсказания, полученные от базовых алгоритмов\n",
    "        # =======================================\n",
    "        predictions = np.array(predictions)\n",
    "        y_pred = np.reshape(stats.mode(predictions, axis=0)[0], (-1, ))\n",
    "        \n",
    "        return y_pred\n",
    "  \n",
    "# # My small debug test\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# estimator = BaggingClassifier(DecisionTreeClassifier(), 4, items_rate=0.4, features_rate=0.8)\n",
    "# X = np.eye(10)\n",
    "# y = np.arange(10)\n",
    "# estimator.fit(X, y)\n",
    "# estimator.predict(np.eye(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare\n",
       "0         0       3    1  22.0   7.2500\n",
       "1         1       1    0  38.0  71.2833\n",
       "2         1       3    0  26.0   7.9250\n",
       "3         1       1    0  35.0  53.1000\n",
       "4         0       3    1  35.0   8.0500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "titanic = pd.read_csv('./data/train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "\n",
    "sex_encoder = LabelEncoder()\n",
    "titanic.Sex = sex_encoder.fit_transform(titanic.Sex)\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare']\n",
    "\n",
    "print titanic.shape\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "\n",
    "X_train_size = 500\n",
    "X_train, y_train, X_test, y_test = X[:X_train_size], y[:X_train_size], X[X_train_size:], y[X_train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно обучить свой беггинг на датасете титаник, и посмотреть работает ли он. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976 0.787723785166\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 10 моделями\n",
    "# =======================================\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите эксперименты:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98799999999999999, 0.78772378516624042)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 100 моделями\n",
    "# =======================================\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 100)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80000000000000004, 0.76982097186700771)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите LogsiticRegression \n",
    "# =======================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'items_rate': 1, 'features_rate': 0.9}\n",
      "0.812\n",
      "CPU times: user 2.6 s, sys: 20 ms, total: 2.62 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Finding good values for items_rate and features_rate\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "classifier = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "# print classifier.get_params().keys()\n",
    "param_grid = {'items_rate': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1],\n",
    "              'features_rate': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1]}\n",
    "optimizer = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "optimizer.fit(X_train, y_train)\n",
    "print optimizer.best_params_\n",
    "print optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 111)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Workclass_ ?</th>\n",
       "      <th>Workclass_ Federal-gov</th>\n",
       "      <th>Workclass_ Local-gov</th>\n",
       "      <th>Workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_ South</th>\n",
       "      <th>Country_ Taiwan</th>\n",
       "      <th>Country_ Thailand</th>\n",
       "      <th>Country_ Trinadad&amp;Tobago</th>\n",
       "      <th>Country_ United-States</th>\n",
       "      <th>Country_ Vietnam</th>\n",
       "      <th>Country_ Yugoslavia</th>\n",
       "      <th>Target_ &lt;=50K</th>\n",
       "      <th>Target_ &gt;50K</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  fnlwgt  Education-Num  Capital Gain  Capital Loss  Hours per week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   Workclass_ ?  Workclass_ Federal-gov  Workclass_ Local-gov  \\\n",
       "0           0.0                     0.0                   0.0   \n",
       "1           0.0                     0.0                   0.0   \n",
       "2           0.0                     0.0                   0.0   \n",
       "3           0.0                     0.0                   0.0   \n",
       "4           0.0                     0.0                   0.0   \n",
       "\n",
       "   Workclass_ Never-worked   ...    Country_ South  Country_ Taiwan  \\\n",
       "0                      0.0   ...               0.0              0.0   \n",
       "1                      0.0   ...               0.0              0.0   \n",
       "2                      0.0   ...               0.0              0.0   \n",
       "3                      0.0   ...               0.0              0.0   \n",
       "4                      0.0   ...               0.0              0.0   \n",
       "\n",
       "   Country_ Thailand  Country_ Trinadad&Tobago  Country_ United-States  \\\n",
       "0                0.0                       0.0                     1.0   \n",
       "1                0.0                       0.0                     1.0   \n",
       "2                0.0                       0.0                     1.0   \n",
       "3                0.0                       0.0                     1.0   \n",
       "4                0.0                       0.0                     0.0   \n",
       "\n",
       "   Country_ Vietnam  Country_ Yugoslavia  Target_ <=50K  Target_ >50K  Target  \n",
       "0               0.0                  0.0            1.0           0.0     0.0  \n",
       "1               0.0                  0.0            1.0           0.0     0.0  \n",
       "2               0.0                  0.0            1.0           0.0     0.0  \n",
       "3               0.0                  0.0            1.0           0.0     0.0  \n",
       "4               0.0                  0.0            1.0           0.0     0.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "adult = pd.read_csv(\n",
    "    './data/adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")\n",
    "\n",
    "adult = pd.get_dummies(adult)\n",
    "adult[\"Target\"] = adult[\"Target_ >50K\"]\n",
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train_size = 20000\n",
    "X_train, y_train, X_test, y_test = X[:X_train_size], y[:X_train_size], X[X_train_size:], y[X_train_size:]\n",
    "\n",
    "print adult.shape\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.98765000000000003, 0.84849932330228484)\n",
      "CPU times: user 5.39 s, sys: 12 ms, total: 5.4 s\n",
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.85765464533078573)\n",
      "CPU times: user 55.9 s, sys: 68 ms, total: 56 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 100)\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.79990000000000006, 0.79515962104927951)\n",
      "CPU times: user 392 ms, sys: 0 ns, total: 392 ms\n",
      "Wall time: 382 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'items_rate': 0.75, 'features_rate': 0.75}\n",
      "0.85015\n",
      "CPU times: user 1min 26s, sys: 100 ms, total: 1min 26s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "# print classifier.get_params().keys()\n",
    "param_grid = {'items_rate': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "              'features_rate': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 1]}\n",
    "optimizer = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "optimizer.fit(X_train, y_train)\n",
    "print optimizer.best_params_\n",
    "print optimizer.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответте на вопросы:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "__Работает ли бэггинг лучше чем линейная модель?__\n",
    "В обоих тестах BaggingClassifier показывает лучший результат, чем линейная модель, как на обучающей, так и на тестовой выборках. При этом композиция с 100 базовыми алгоритмами дает лучшие предсказания, чем композиция с 10 базовыми алгоритмами.\n",
    "\n",
    "__Какой items_rate и features_rate работает лучше и почему?__  \n",
    "В тесте _Titanic_ оказалось оптимальным генерировать обучающие выборки из всех объектов исходной выборки и при этом для каждого базового алгоритма рассматривать 90% всех признаков.\n",
    "\n",
    "В тесте _Adult_ оказалось оптимальным при обучении базовых алгоритмов использовать три четверти объектов, и три четверти признаков.\n",
    "\n",
    "Судя по всему, это объясняется тем, что тест _Titanic_ содержит малое количество объектов (891), что не позволяет алгоритму достаточно качественно обучиться при \"выбрасывании\" части объектов. В свою очередь, тест _Adult_ содержит много объектов (32561), которых достаточно не только для качественного обучения, но и для реализации бэггинга. Также, возможно, целевая метка сильно зависит от всех признаков, поэтому при обучении базовых алгоритмов в обоих тестах используются почти все признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Text, Image Classification</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше в каждом эксперименте нужно: \n",
    "- сравниться с линейной моделью ( какую лучше выбрать?=) )\n",
    "- сделать выбор в пользу одной из моделей\n",
    "- выбор обосновать, почему одна из моделей хуже а другая лучше\n",
    "- что такое хуже и лучше\n",
    "- попробуйте беггинг над деревьями и линейными моделями \n",
    "- почему работает или не работает, какие особенности данных на это влияют"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train, y_train = vectorizer.fit_transform(newsgroups_train.data), newsgroups_train.target\n",
    "X_test,  y_test  = vectorizer.transform(newsgroups_test.data), newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n",
      "(11314,)\n",
      "[ 7  4  4  1 14]\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868658299452 0.752124269782\n",
      "Features deleted: 128499 / 130107\n",
      "CPU times: user 19.1 s, sys: 28 ms, total: 19.1 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите Линейную модель \n",
    "# =======================================\n",
    "\n",
    "# 1. Обучим логистическую регрессию с l1-регуляризацией (Lasso).\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l1')\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "features_left = np.count_nonzero(clf.coef_)\n",
    "print 'Features deleted: {} / {}'.format(X_train.shape[1] - features_left, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969860350009 0.827934147637\n",
      "CPU times: user 45.1 s, sys: 780 ms, total: 45.9 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2. Обучим логистическую регрессию с l2-регуляризацией (Ridge).\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993636202934 0.854753053638\n",
      "CPU times: user 3.61 s, sys: 80 ms, total: 3.69 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3. Обучим классификатор на основе стохастического градиентного спуска (SGD)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть, классификатор на основе стохастического градиентного спуска дает наилучший результат. Честно говоря, я не знаю, как это объяснить. Я ожидал, что наилучший результат будет у логистической регрессии с l1-регуляризацией (Lasso), т.к. в данных огромное число признаков, многие из которых наверняка избыточны и могли бы быть обнулены с помощью l1-регуляризации, оставляя лишь те, которые действительно влияют на целевые метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989482057628 0.631970260223\n",
      "CPU times: user 6min 27s, sys: 824 ms, total: 6min 28s\n",
      "Wall time: 6min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import load_cifar10\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10('./data/cifar10')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train.reshape(X_train.shape[0], -1), X_test.reshape(X_test.shape[0], -1)\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21284 0.1964\n",
      "CPU times: user 33.8 s, sys: 16 ms, total: 33.8 s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучим классификатор на основе стохастического градиентного спуска (SGD), т.к. \n",
    "# он способен отработать за адекватное время на данных такого масштаба\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99362 0.375\n",
      "CPU times: user 51min 33s, sys: 19.5 s, total: 51min 53s\n",
      "Wall time: 52min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), 10)\n",
    "clf.fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Random Forest Feature Impotance</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Опишите как вычисляется важность фичей в дереве, можите изучить как работает  feature\\_importances_ в sklearn.\n",
    "\n",
    "---\n",
    "\n",
    "При построении решающего дерева происходят разбиения вершин. При разбиении вершины на две критерий Джини двух новых вершин меньше критерия Джини родительской вершины. Если зафиксировать конкретный признак $k$ и просуммировать изменение критерия Джини по всем вершинам, в которых происходило разбиение по признаку $k$, то получим важность признака $k$. Т.е., если в вершине $v$ произошло разбиение по признаку $k$, то в сумму необходимо добавить разность между критерием Джини в вершине $v$ и критерием Джини в ее предке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Почитайте Feature Impotance для Adult и Titanic (используйте полный датасет), ПРОИНТЕРПРЕТИРУЙТЕ резульататы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.13357977e+01   1.68730886e+01   1.09871352e+01   1.04427259e+01\n",
      "   3.79384541e+00   6.45116928e+00   1.54181183e-01   5.06054523e-01\n",
      "   6.14855385e-01   0.00000000e+00   1.00528588e+00   6.61686532e-01\n",
      "   8.80579449e-01   4.57376567e-01   9.30268723e-04   6.35133262e-02\n",
      "   6.38527635e-02   4.88109627e-02   7.85148325e-03   1.92973781e-02\n",
      "   4.73700219e-02   4.98730166e-02   1.40705989e-01   2.62921345e-01\n",
      "   2.62920070e-01   7.02222142e-02   3.38385741e-01   2.64721265e-01\n",
      "   7.48336709e-03   1.21636191e-01   4.14911092e-01   2.27228718e-01\n",
      "   5.11526598e-02   1.95479134e+01   6.68555864e-02   1.90228035e-01\n",
      "   1.11632223e-01   1.08591128e-01   1.41401336e-01   6.18514199e-01\n",
      "   1.71535651e-03   8.48215931e-01   1.20923750e+00   3.67192940e-01\n",
      "   3.04704484e-01   5.44535260e-01   4.53637794e-01   8.12604584e-04\n",
      "   8.82065413e-01   3.48070852e-01   7.89393979e-01   5.58488593e-01\n",
      "   5.68289244e-01   2.41976785e-01   2.27471090e-01   1.14910350e-01\n",
      "   1.60610188e-01   1.41586147e-01   4.23825856e-01   9.31186121e-02\n",
      "   1.88407694e-01   3.95742932e-01   6.67971238e-02   5.17353399e-01\n",
      "   4.32761942e-01   4.53478732e-01   2.46014567e-01   2.90556638e-02\n",
      "   1.14613927e-01   2.63871358e-02   7.24157274e-03   7.56569790e-02\n",
      "   8.69373774e-03   6.82451620e-03   2.09651085e-03   1.01095263e-01\n",
      "   1.89227779e-02   1.14739364e-01   2.40567100e-02   1.52104186e-03\n",
      "   3.45582809e-03   0.00000000e+00   9.36096179e-04   8.51694406e-03\n",
      "   1.54255883e-02   1.07117022e-01   5.50151424e-02   2.56909946e-02\n",
      "   1.00369657e-01   5.89853379e-02   7.54023073e-02   1.90317141e-04\n",
      "   1.06634967e-01   3.56576480e-03   0.00000000e+00   3.64897678e-04\n",
      "   9.51632613e-02   7.47736037e-02   3.24891281e-02   4.24068131e-02\n",
      "   4.40384613e-04   6.56370397e-02   2.72514122e-02   3.79715682e-03\n",
      "   0.00000000e+00   5.01705856e-01   2.10254642e-02   4.96131156e-02]\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Посчитайте feature_importances для clf\n",
    "# =======================================\n",
    "def feature_importances(clf, X):\n",
    "    res = np.zeros((X.shape[1], ))\n",
    "    for estimator in clf.estimators:\n",
    "        res += estimator.feature_importances_\n",
    "    return res\n",
    "\n",
    "importances = feature_importances(clf, X_train)\n",
    "print importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9  81  94 104]\n",
      "Index([u'Workclass_ Never-worked', u'Country_ Holand-Netherlands',\n",
      "       u'Country_ Outlying-US(Guam-USVI-etc)', u'Country_ Trinadad&Tobago'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "unused_features = np.where(importances == 0)[0]\n",
    "print unused_features\n",
    "print adult.columns[unused_features]\n",
    "# Видим, что признаки 9, 81, 91, 104 абсолютно не участвуют в построении деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Посчитайте feature_importances для clf\n",
    "# ======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.14927042  33.44345425  24.95172909  33.45554624]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "importances = feature_importances(clf, X_train)\n",
    "print importances\n",
    "print np.where(importances == 0)[0]\n",
    "# А здесь все признаки информативны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
